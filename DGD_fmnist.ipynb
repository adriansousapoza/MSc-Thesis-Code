{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "    folder_path = '/content/drive/My Drive/Colab Notebooks/TorchGMM'\n",
    "    import os\n",
    "    files = os.listdir(folder_path)\n",
    "    print(files)\n",
    "    os.chdir(folder_path)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "folder = 'plots/FMNIST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Allocated memory: 0.4580078125 MB\n",
      "Reserved memory: 2.0 MB\n",
      "Total memory: 7836.25 MB\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.cm as cm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.manifold import TSNE\n",
    "if 'umap' not in globals():\n",
    "    !pip install umap-learn\n",
    "import umap\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "\n",
    "import utils\n",
    "import utils.metrics\n",
    "import utils.gmm\n",
    "import utils.representation_layer\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "importlib.reload(utils.metrics)\n",
    "importlib.reload(utils.gmm)\n",
    "importlib.reload(utils.representation_layer)\n",
    "from utils.metrics import ClusteringMetrics\n",
    "from utils.representation_layer import RepresentationLayer\n",
    "from utils.gmm import GaussianMixture\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "    print('Using device:', torch.cuda.get_device_name(device))\n",
    "    print(f\"Allocated memory: {torch.cuda.memory_allocated(device)/1024**2} MB\")\n",
    "    print(f\"Reserved memory: {torch.cuda.memory_reserved(device)/1024**2} MB\")\n",
    "    print(f\"Total memory: {torch.cuda.get_device_properties(device).total_memory/1024**2} MB\")\n",
    "\n",
    "random_state = 0\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 60000\n",
      "Test dataset: 10000\n",
      "Image shape: torch.Size([1, 28, 28])\n",
      "Image size: 784\n",
      "Plotting 10 images.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAErCAYAAAAL/58RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjXElEQVR4nO3deXzU1fU//jN7MlnJQkJYwy6CLAoooAJaUKtgRaqgFdyt/Vi11mqttlq1tdS9tlZr1brvuFSqKAoKbuyoLMq+E0L2ZZJZ7u8Pf+TLOeeSmYR3QoDX8/Ho49Hznnvf887MnfdcxnPudRljDAEAAAAAgGPcB/sCAAAAAAAON5hkAwAAAAA4DJNsAAAAAACHYZINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADsMkGwAAAADAYZhkw2GnW7du5HK54v7v6aefPtiX2iR7r7slLF68mCZPnkx5eXmUlJREhYWFdM0111BRUVGLPF9jEnnv3nzzzVa5lo0bN5LL5aJu3bo1ue/ecbhx40bHr8spo0ePbnhNJ06c2GjbV199lb0HW7duZY9Pnz694bH/+7//2+957rrrLnK5XDR9+nR2fO9rvb/XrLy8nO666y4aPnw4ZWRkkM/no7y8PBowYAD97Gc/o8cee4yqq6vVtTTlf235vTqY9r6eh9o9E+Bg8x7sCwBoKSNHjqSePXvu9/HGHjuSvPbaazRlyhSKRCI0dOhQKiwspEWLFtEjjzxCr776Ks2fP/+gvFbjx4+n/Px862NdunRp5as5/M2aNYt27dpFeXl51sf//e9/J3yuxx9/nK6//nrq0aOHI9e2Zs0aOvXUU2nr1q0UCARo+PDhVFBQQKFQiFatWkXPPfccPffcczRy5Ejq378/jRo1ynqe1157jaqrq/d7b0hNTXXkegEAiDDJhsPYZZddpn4tA2779u00bdo0ikQi9Nhjj9EVV1xBRETRaJSmT59Ozz33HE2dOpW+/PLLFvsVfX9uvvlmGj16dKs+p5PmzJlD4XCYOnbseLAvJa7jjjuOFi1aRM888wzdeOON6vEtW7bQBx98QEOHDqWFCxc2eq5gMEg1NTX0u9/9jl566SVHru/CCy+krVu30pgxY+jll1+m3Nxc9vjmzZvpP//5T8Mk+bLLLqPLLrtMnWfu3LlUXV2NewMAtAqkiwAcwR588EGqqamhU089tWGCTUTk8Xjo0UcfpYyMDFq4cCHNnj37IF7loalHjx7Ut29f8vl8B/tS4rrwwgvJ7/fTU089ZX386aefplgsRpdcckncc1166aWUmppKr7zyCi1ZsuSAr23dunW0aNEiIiL65z//qSbYRD/8l43bbrutWWk9AAAtBZNsgP/fvjnP//rXv+jYY4+llJQUyszMpDPOOIO++OKL/fYtKSmhW265hY4++mgKBoOUlpZGxx57LM2YMYNqa2v322/btm1044030oABAygtLY1SUlKod+/eNH36dPrss8/22+/111+nUaNGUXp6OqWkpNDIkSNp1qxZTf6bZ86cSUREU6dOVY+lpqbShAkTiIjojTfeaPK5W1o4HKbnnnuOLrjgAurbty+lp6dTcnIy9enTh375y1/S9u3brf3Ky8vp1ltvpQEDBlBKSgoFAgEqKCigkSNH0u9//3sKh8PWfsYYevzxxxvGRUZGBo0bN44+//xza/vGcrJramronnvuoSFDhlBaWhoFg0E6+uij6dZbb6XS0lLVft/c8KZeRyKys7NpwoQJtGrVKnUeYww9/fTTlJycTFOmTIl7rvbt29MNN9xAxhi66aabmn1Ne+3atYud+2Br6vj58MMP6ZprrqFBgwZRTk4OBQIB6tSpE5133nn7/a8Ct99+O7lcLrr99ttp+/btdNlll1FBQQElJydT//79WerO6tWraerUqZSfn09JSUk0cOBAevnll63n3XdMzpw5s+EekpaWRqNHj27WPYToh5qOCy64gLp06UKBQICysrJo/Pjx+z3fjh076Nprr6XevXtTUlISBYNB6ty5M51yyil07733NusaANokA3CY6dq1qyEi89RTTzWpHxEZIjLXX3+9cblcZtSoUWbKlCmmf//+hoiM1+s1b7zxhuq3bt26hufMzc01kyZNMhMmTDBpaWmGiMyQIUNMSUmJ6vfhhx+azMxMQ0Smffv2ZuLEiWby5Mlm6NChxufzmWnTplmv7/e//71xuVxm5MiR5rzzzjMDBw40RGRcLpf1+vanoqKi4ZwrVqywtnnooYcMEZmhQ4cmfN4DtfeaPv7440bbbdmyxRCRycjIMMcff7yZPHmyOeOMM0xBQUHDe/H999+zPtXV1Q3vZ25urjnrrLPM+eefb0aPHm3y8/MNEZnS0tKG9hs2bDBEZLp27WqmTZtmfD6fGTt2rPnpT39qevfubYjIBAIB88UXX6jr2zsmNmzYwI7v2bPHDBo0yBCRSU9PNxMmTDCTJk0yOTk5hohMYWGh6nMg19GYk08+2RCRefbZZ82sWbMMEZnLLruMtZkzZ44hInPBBRcYY/7f+7NlyxbWbtq0aYaIzJ133mkqKytN+/btDRGZ2bNns3Z33nmnISI1vvf+jfI12/s+E5G5/fbbm/T3Sc29N+zV1PFjjDE9evQwfr/fDB482EyYMMGcc845pl+/fg33lNdee009zx/+8AdDRObiiy82+fn5pkuXLuanP/2pGTNmjPF4PIaIzL333ms+//xzk5aWZvr06WPOP/98c8IJJzS8Vi+99NJ+//7rr7/eEJE57rjjzJQpU8ywYcMa+j388MOq39731va6Pfjgg8btdhsiMoMGDTLnnnuuGTVqlPH7/YaIzB133MHa79ixo+Ez2qVLFzNx4kRz3nnnmRNPPNFkZWWZjIyMJr0nAG0ZJtlw2DnQSXZycrKZM2cOe2zGjBkNE7pdu3axx4YPH26IyEyYMMFUVVU1HC8qKjJDhgwxRGSmTp3K+mzevNlkZGQYIjI333yzqaurY4/v2rXLfPrpp9bry8zMVJOpvV/KvXv3TvjvXbFiRcM5y8rKrG3eeOMNQ0QmJycn4fMeqEQn2RUVFeatt95Sr119fb357W9/a4jInHHGGeyx//znP4aIzOmnn27q6+vZY9Fo1MydO5edb9+JX9euXc2aNWsaHotEIuaSSy4xRGTGjRunrm9/k+zzzjvPEJEZPny4KS4ubjheWVlpTj/9dENEZsSIEazPgVxHY/adZEejUdOpUyeTlpZmqqurG9pccMEFhojMRx99ZIxJbJJtjDEPP/xwwz8yY7FYQ7umTrKNMWbixIkNj/Xr18/8+te/Ni+//LJZu3Ztk/7eA51kN3X8GGPMzJkzrf/InjlzpvF6vSY7O9vU1NSwx/Z+nonIXHXVVSYcDjc89vbbbxsiMmlpaaZr167mrrvuYq/vgw8+aIjI9OzZUz3n3r/f5XKZ5557jj320ksvGZfLZbxer/n666/ZY/ubZL/33nvG5XKZnJwcM2/ePPbYihUrTKdOnQwRmblz5zYcv+OOOwwRmSuuuIJdtzE/fHY//PBDdd0AhypMsuGws/eLJN7/5C9Oe49fd9111vMed9xxhojM3Xff3XDs008/NURkgsGg2blzp+qzaNEiQ0TG7XazScl1111niMicddZZCf9djf3SFAqFGibtmzdvTuh8CxYsaDjnvl/i+5o9e7YhIuP3+xO+zgMV732Tk7P9KSgoMG6321RUVDQc2/uPpfvvvz+hc+w78Xv77bfV4zt27Gj4FVlOumyT7E2bNhm3221cLpdZvny5Ot/WrVtNUlKSISKzYMECR66jMftOso0x5ne/+50hIvP0008bY4wpKyszycnJpnv37g0TokQn2fX19aZ79+6GiMyLL77Y0K45k+yKigpz4YUXGpfLpcZDp06dzG9/+1vrRFY60El2U8dPPFOmTDFEZN599112fO8ku0uXLqa2tlb1O+aYYwwRmWHDhqmJajgcNllZWYaIzKZNm9hje//+s88+23o9kyZNMkRkLr/8cnZ8f5PsvT8w2H6NN8aYV155xRCRmTRpUsOxq6++2hBRk/6rG8ChCquLwGEr3hJ+fr/fenzatGnW4xdddBEtWrSI5s6dS7fccgsR/bBaARHRaaedZl367Nhjj6WBAwfS8uXLad68eXTBBRcQEdF7771HRMSKDRN11llnqWOBQIC6d+9OS5cupW3btlHnzp2bfN62Zn9L+Mnl2ZYvX05z5syhDRs2UHV1NcViMSIiikQiFIvFaO3atTR48GAiIho6dCgREc2YMYOys7PpzDPPpKysrLjX4vV66bTTTlPH8/PzqV27dlRaWkp79uzZ75KDe33yyScUi8VoyJAhdMwxx6jHO3bsSOPHj6e33nqLPv74YxoxYkSLXMf+XHzxxfSnP/2JnnzySZo2bRq98MILVFtb27BOclP4fD666667aOrUqXTrrbfSpEmTml0EmpaWRs8++yz98Y9/pDfffJM+++wzWrJkCa1fv562bt1Kf/7zn+n555+nefPmtWjxY3PHz/bt2+ndd9+l1atXU3l5OUUiESIi+vbbb4nohyUKzzjjDNVvzJgxlJSUpI736tWLVqxYQaeffrp6X7xeL3Xr1o1KSkpo+/bt1uUu93ePmzZtGr3++usN97XGFBcX01dffUXJycnWexIRNawOtG99ybBhw+gf//gH3XzzzWSMoXHjxmHpRDhsYZINh63mLtNVWFjY6PF9N+HYtm1bo32IflhlYvny5Q1tiYg2bdpERER9+/Zt8vXtb43o9PR0IiIKhUIJnSctLa3h/1dXV1NGRoZqU1VVxc4dz+rVq+mee+5Rx0eNGmVdUq0x8Zbwq66upp/97GcNxZv7U1FR0fD/R48eTTfddBP99a9/pWnTppHL5aJevXrRyJEjaeLEiXTWWWeR263rwTt06LDfCWJ6ejqVlpYm9LonOl72bdsS19HYc5900kn0ySef0Lp16+jJJ58kt9vd7OXuzj//fPrrX/9KS5cupccee6zRTWoSUVhYSNdffz1df/31RPTD5+jf//43zZgxgzZv3ky/+MUv6N133z2g52hMc8bPHXfcQXffffd+C2qJ+Bjd1/4+63snpft7fO9ne39joSn3uP3ZsGEDGWOotraWAoFAo213797d8P9/9rOf0QcffEDPP/88TZo0iTweD/Xr149GjRpF5557Lo0dOzbucwMcKjDJBmgiY8xBfX7bJLA5unbt2vD/N2/eTAMGDFBttmzZQkSU8K+DO3fupP/85z/Wx5o6yY7nt7/9Lc2cOZP69u1L99xzDw0dOpRycnIa/gvFiBEj6PPPP1fv1z333ENXXXUVvfPOOzR//nxasGABPfXUU/TUU0/R0KFD6eOPP6aUlBTWx6nX/EC1xnVccsklNG/ePLr++utp0aJFNG7cuGb/lxGXy0X33HMPjR8/nu68807H16bu2rUr/fGPf6R27drRr371K5o9ezbV1tZScnKyo8+zr6aMnzfeeINuv/12Sk1NpUceeYTGjh3bsEqIy+WiW265hf785z/v954S7/1uqfGQyD1u738xSk1NpUmTJiV8brfbTc899xzdcsst9O6779KCBQtowYIF9Oijj9Kjjz5KZ511Fs2cOZM8Hk+zrx+grcAkG0DYsGEDDRo0SB3fuxRbp06dGo7t3Whk/fr1+z3f3sf23ZSkS5cutGbNGlq9evVB23kyPT2devbsSWvXrqVFixZZJ9l71yceMmRIQuccPXp0q/0j5JVXXiEiopdfftmaevH999/vt2+3bt3ommuuoWuuuYaIiBYuXEgXXnghLVy4kGbMmEF33HFHi1xzc8dLazr33HPpmmuuoXfeeYeIKKG1sRszbtw4OuWUU2jOnDl03333tcjkady4cUT0Q4pQWVlZi06yiRIfP3vH6N13321NDWtsjLakDRs20MCBA9Vx2z1uf/b+w8vlcjX8F4+m6NevH/Xr149uvPFGMsbQRx99RFOnTqV33nmHnnnmGbr44oubdD6Atqht/DwD0IY8++yzjR7fN4Vh7/9/77332Hq+ey1dupSWLVtGbrebTjrppIbje/Nq//Wvfzl01c3zk5/8hIiIXnjhBfVYVVVVw0TrnHPOadXrSkRJSQkR8V/k93r//fepuLg44XMNHTqUrr76aiIiWrZsmSPXZ3PSSSeR2+2mZcuW0fLly9XjO3bsaMjXHzNmTItdR2OCwSBNnz6dsrOzqbCwkM4+++wDPudf/vIXcrlcdN9997HUgUQk8o+2zZs3E9EPtQk5OTnNusYDsb/x09gYLSoqog8++KBVrk/a3z3umWeeISJqNE1rr4KCAjrmmGOosrKyYcw2l8vlolNOOaVhvf6W/AwCtCZMsgGERx99VBX+PPDAA/TVV19RWloaXXrppQ3HR40aRcOHD6fa2lq68sorqaampuGx4uJiuvLKK4noh9zUff+T+69+9StKS0ujt99+m2699VaVr1lUVETz589vgb+Ou+666ygYDNKHH37IJvzRaJSuvvpqKisro6FDhzb8UtiWHHXUUURE9Le//Y0dX7NmDV111VXWPjNnzmwoPtxXOBxumCjYJkRO6dKlC02ePJmMMXTllVfSnj17Gh6rrq6mK664gkKhEI0YMUIVPbamhx56iIqLi2n9+vVx820Tceyxx9LkyZOpsrKSnnjiiSb1XbFiBY0ZM4ZmzpxJ9fX16vHly5fTtddeS0R0QMWViWjq+Nk7Rh9//HF27eXl5TRt2jQqLy9vsWttzMyZM9WW96+99hq9/vrr5PV6G36hj+euu+4ioh8KZvf+g3xfxhj68ssv2Y6xzzzzDC1evFi1raysbLjvtuRnEKA1IV0EDltPPPFEo1Xy48aNs+50eOWVV9LYsWPpxBNPpI4dO9I333xDX3/9NXk8HnryySfVyg0vvPACjR07lt566y0qLCykk046icLhMH388cdUUVFBQ4YMoUceeYT16dKlC7322mt07rnn0t13301PPPEEnXDCCeTz+WjTpk20dOlSmjp1qlpJw2kFBQX09NNP05QpU+iKK66gf//739StWzdauHAhrV+/nvLy8uiFF15o8soSreEPf/gDnXvuuXTbbbfRK6+8QkcffTQVFRXRp59+SieeeCIVFBSoXTPnzZtHDz30EOXk5NDgwYOpffv2VFlZSV988QUVFRVRx44d6Te/+U2LXvff//53Wr16NX355ZfUo0cPGjNmDHm9Xpo3bx7t3r2bCgsL6fnnn2/RazgY7r77bpo5cyb7h2gijDE0d+5cmjt3LqWkpNDgwYOpY8eOVF9fTxs2bGj41XPQoEH04IMPOn/h+2jq+LnuuuvomWeeoVmzZlH37t3p+OOPp3A4TPPmzaNgMEiXXHIJPfnkky16zTbXXnstTZkyhe6//37q1asXrVu3jr788ksiIrr33nut6Vc2Z511Fj300EN0ww030IQJE6hnz57Up08fysjIoN27d9Py5cupqKiIbrrppoZ/qL/xxhs0bdo0KigooEGDBjWsirNgwQIqLy+n/v370+WXX95ifztAa8IkGw5bewtq9iczM9M6yX7ggQeoT58+9Nhjj9HChQvJ5/PRaaedRrfddpv118Xu3bvTkiVL6N5776U333yT/vvf/5Lb7aY+ffrQeeedR7/85S+tOaLjxo2jb775hu6//35677336L333iOv10sFBQX0s5/9rNW+aCZPnkzdu3enP/3pT/Tpp5/S0qVLqUOHDvSLX/yCbrvtNuvShG3BOeecQ/PmzaM77riDli9fTuvWraPu3bvT7bffTr/+9a+tv75Pnz6dkpOTaf78+bRy5UqaN28eZWRkUJcuXei6666jK664grKzs1v0urOzs+mzzz6jhx9+mF5++WWaPXs2xWIxKiwspMsvv5x+/etfU7t27Vr0Gg6Gnj170uWXX07/+Mc/mtSvf//+NG/ePJozZw598skntHnzZlqyZAlFIhHKycmh0047jc455xyaPn16i/6KTdT08VNYWEhLly6lW2+9lT799FP673//S/n5+TRlyhS6/fbb6dFHH23R692fa6+9lkaMGEEPPPAAvf3222SMoRNPPJF+85vf0Jlnntmkc/3yl7+ksWPH0t/+9jf6+OOPac6cOeR2uyk/P58GDx5MP/7xj1lh5A033ECFhYUNyzCWlJRQVlYW9evXj6ZOnUoXX3yxKjwGOFS5zMFeKgGgjdj7ay0+EgBwOOrWrRtt2rSJNmzY0KLriQPAD5CTDQAAAADgMEyyAQAAAAAchkk2AAAAAIDDkJMNAAAAAOAw/JINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMMS3ozmR+7JLXkd0EZ8EHu1xZ+jxcaS3JXQqXKDYQNY2O6BbSz+5p2+qkv7JXz7Z09dlMWuer4tMxFR8cAg73PmHhbv2ag3KOl75wYWR3cVqTYHyyE9lhzg7dpZHfv+yk4s7vWv7SyObNjUItcSO3kwi/f0S1Jt2j+5hMWmrq5FrqU5jrSx5O7P7ynbf5Sl2rQ7nY+dHaXpLG7/kt4AK+3TtSwODSlk8YZz9O9uFxz/OYt31fHn+fyNgapPx798po61FUfaWGrLPD35+Iuu3bCflm1TImMJv2QDAAAAADgMk2wAAAAAAIdhkg0AAAAA4LCEc7IBDqpE8q3j5GBHRw9Rx9adxz8Cd4x5Q7UJGZ7n3M23m8Xtr/yf6jMoEGj0WhLx7/J8Foe7e1Sby3+yhcUL6vi/m3++9ALVp+P9Pha7Fixr5hXCvjzteM785p/qnOyrJ85icemPU1j8dXmB6lMdDojYz+L8lArVJ8MXYvGP2r3J4t9+Okn1cUX55yPn8c9VGzhwFVOPZ3HHn69VbUrraljc1Vemz1PH8+oHd9rK4mvu+1D1GZnE7w+vV/H86uoYH1tERJ+W92Hx5io+zvue+Z3qc/JFpSx+YOGpLO41fbHqAy0jewF/v/qk7lJtvq3swOKqK3NYHP12TZOfV+ZbExFNeoffU/J9q1n8bukg1Wfjj/j9L1pW3uRrOZjwSzYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADsMkGwAAAADAYSh8hENDAhvLeHKyWVz7YiqLf971ddXH7+KbxGysz1Ftiup5cdA31R1ZHDG6IDHZzTej6ZXMi0221uvNJcLiPDHjUm2km0PtWZzjq2LxjUd/oPpkPs2Lqv7w7VmqTf7Zq+I+N3DRUl7s5S/XY/bFe05n8QnXLWTx9A4LVJ8Tk4pZ3M7DNy36tr5W9dkY4cVONyzhm2MUvK/HbH2qOgQOcA88isXVP+WFW4tX6QIxdzDCYpdbjyUT4/eHzRF+//td9Tlxry0S47+zRS33nJIKXpwbjfI+sYj+rW7p4p4s9nXg95zvHh+q+vS+YqE6Bgcu4OFjaXjKOtXm9PTlLM7/H9+Ian2YfwcSEV0yfzqL3z35ERYnuearPrtjvIhxZR3/Lu2axDdgIyJaV5aijh1K8Es2AAAAAIDDMMkGAAAAAHAYJtkAAAAAAA47cnOy5eYmRHHzfj3ZOo+2dHxvFqe/8EWTn9vl5ZuDmDDP5202298oJZDrfKhIf4v/Ledn8/zWLyt7qD4yDzrZE1ZtaqP8/XG7+PP4XTznzdZmRTXfmMQrcsFtfAm0kYrq01hcHNaJtjLX+86j31Jt/j5MbFby1ddNvpYjXcyvP3/eshiL5z01jMW+S/R7XhLl72GWh+fdrwr1Un2eXs03PMl7NpnF5YWWOoLdMXUMDtx3N/JNY2LF+rWXZA52IKDvS5EIP09Y5EZv2qzrS9wV/Cs/lsTfc1dMj1njjzMuLH3Iy68/uoXXEeQepXNvyy/kYzbjuQS+SyGu78tyWVyfrcffktpuLB6UtJnFJybp77he05aw+P4vf8TiG/Nnqz5fh/j3YIqb535/XclztH9QZjl26MAv2QAAAAAADsMkGwAAAADAYZhkAwAAAAA47IjNyXZ5dF6SifC8I/egfixedaXOb3WLJWp91TzH0lur89l8sxfx500kB1vmcVuun1z830yJnNflPTSHQGTsserYGdk8t3hJdTcWB9369QgQf8/b+ytUmx+l8DWjCzw839Dn0v9WrYzx8wbd/P2qM3pcyLOkuf0sronpvMz1Ef7+/a/yGN4nys9BREQihTJkfKrJd5fxPNLeX+nTQON8VbreoSaHv8vpm/g4WXjbcarPnM48VzWUw9/A9I16LOUX89zumlyxBrvtY59ACQc0Xddn+Gtffg2/x5Tu4XUURESmiH/+alItb5hlfep9ueot+dU5/B6oWlToe4Er1PTf4tziuaPpfDzu3pap+vRGDnaL2LaJr5+e0qtOtZHfAXtifG1qjysU93m+2N6Vxb076/Wt3xfrZOf7ylicF9Dfv7vjPnPbhl+yAQAAAAAchkk2AAAAAIDDMMkGAAAAAHAYJtkAAAAAAA47NKveHGAr+JOFj1vGZ7L4ghM+VX0W7O7O4k2BfH5OvgcEERF5Tz2Bxb3/sY3FkY18IfgfTsSLqOS12njateMHonqji2iFLjQ4FGwdqwv6sr18k4523hoWy41niIiS3LyYsDisi5DO/8cNLE7ZzgvN0jbpQpKqzrzAI3Ubb2PcuijJXc/PGw2IzSbS9fUXDebj+I9Tnmfx4upC1UcWgIaN/iw8MOZFFj9KPVUbaJw7Ytvoib/vNTnxNyYJFvNxkbqTnzcctBTeduLvqdzXyGW7tMNnX6o2RRa61xw/gsXDxq9Wfb5ayjcYcnn1m+MO8s9xrITfc2TxIRGRKeb3TU+dKFBM1s9jxHN7K/l4C2fr76KY+P3OHeRt+lynv+OavvUWJCLtO17UmPQjXUAfM/z92lLPiyXLk9bqPqMGiSN8PBZFq1Uft4vfy1JcvM+mGr3hH1Gx5dihA79kAwAAAAA4DJNsAAAAAACHYZINAAAAAOCwIzYnOxaKv7h6/WCe43tuxiLVRub0znPznKNtH3VWfaLH8PNuup/nAceW8pw9IqLsb3jGWvrSHapN8UkdWbz7WJ5Ll2dZ67/dh+v0wUPAmad/qY5Vi4Xu5XtTF9HDPcdbyeLva/NUm4IZn7G48jy+OciuYTrxvsN9vM+2m/l7mvO1zosL5/DcOePh+ZLBnXozna5/4LvEhM7j57BtwJPj43/z9nCmavPzzG9Z/M9jJ/JrW8wfB82Wd+8StRVukYgas6RohzId+C1EXool/zrmxW40raHLH/m94ewLNqk2y/P4vTy0R99jojV8sHhr+DjxVsV/P1W+dbUea7JkI+YTY7hKD9pYOs/Bzp3NN9eJFu+Je23gjNStfE4ivyeJiHyiaCPNw+dHH9fmqj7/fflfLF4f5t9p71XzzWmIiJJcvI3M0d5WlaH6pCMnGwAAAAAA9oVJNgAAAACAwzDJBgAAAABw2JGTk+0S+WlGJyVW/ZTn2l7Uby6L14V1XlInfwmLJxcs5g0uFDERPbLmZBZXr+d5SO4UfW07j+f/Hto2UV+LCfM8uHZL+NvrnrZL9amo766OHQp+216vWf5fsSZ0QORkt/Px/C+b7sm71bFviK8Z+un9/2Dxtihfj5uI6OTe17N4w1m8z0lf/0T1+eDol1kcdPM1bf+w+2jV54uBPAe7RuTbyfFJRBQyvE84pm8Db1XznNAdJ/Ixmq+HNQj1qTonVqZDekJi/XtLTrZIW1RtTAKp1GIZXBUTEUWT9DE4cC4f/xybMK+TePZ0/n1ARER/iX9ej8jBlmuh29a89tTywSLHkq2PW6ylbRs7uhMPM5/5PIFO0BJSt/L86rJYULWRudFyT4miSLrq83Apr19Kc/PnkXneRETfhfg+InJvC7d1Af9DG37JBgAAAABwGCbZAAAAAAAOwyQbAAAAAMBhmGQDAAAAADjs8Ch8lEWNzXT8TXxjjzGpK+P26Sh2dag2vMilLJqi+vyh37ss3t2bb0YTlqv/E9ET3/PNTKrW60XbPRH+Ohx/yVIWT8paqPrMeH2AOtYWmZGDWPxl3WrVRi6yLwsv5EL4RET5vnIWL63RC+hLZ0yazmJ3rT5vl878vTjj9+NYnObSxZLn1o3nB8RmJmWn9lZ90ojvMPRJKW8zOmuN6iOLWmRMRLQ7wsdk6AReoEIPqi4gWD7GukhR1mPbfvaQbZrRx81roq19bBvhwIGThY5SZP1GfWzDCSz2d63WbUK8gM0jN5+x1Hl76sQBcY/x6qehUHbjGyjZfqoLbPXpg3BQ+LaXsnhSSqlq889yXtgo7/8ey+5Vto3O9lUZ05XUHjEoQzE+TkJhfdNMbfRZ2j78kg0AAAAA4DBMsgEAAAAAHIZJNgAAAACAww6PnGzLxjLN8X1VexbvSefZQDsjmapPtofnqqa5a1nczVes+uyOinwnsUlKvSVH9o6j32Fx6Cid8yZzkEckbWfx5JUXqT4ptF4da4t23ciTCfM9FarNRuIb9NSJfK88kX9NpBfZr4n6VZvIKUNYXJvLz1ubpf+tKp6aqvN7sNit07jJKzYmifp5vmRdpq49CF3FczdHpM5jcVFYbyLQO2kHi235dhkenpw57agvWTyPklUf4Gx5z96axjefsfWROdiWPR4snRp/WOXmQpti3PwNzEitVW32iE1FogHex1dp2QxJ3JfcYhzESbMlosTGX3KRM3VScOAiGzbFbSPnDolsLCNFxW+2QZceTAFRHBIUA7CsXNew5cR95rYNv2QDAAAAADgMk2wAAAAAAIdhkg0AAAAA4DBMsgEAAAAAHHZ4FD46JDfAixjl5iV+l9jRgYi2h9ux+PvaPiz+roIXUxIRnZb3LYvlZiC2QjRZeFDg0wvKhwyvapG1dSPzdJHjMnWkbYp8xV/nv+Scrtqc155vttPLX8Tizh69O8NT5f1ZXBfTH4lZz/yTxWETFbE+b0gcS3KJohC3Llx1i3/z1hn+DvpcuiB2fZi3ebJkJIs7BvQ4kePaZxnX88r6snjB+8ewuCt9pvoAZ90kRpAbwLgsG4gkUhwZ93nEsPbU6XtMbS6K1VqFW7yhMV1UFtzB32TP0ZaBIcaBp07uUqS7xPz8oCfE+0T1/iHkFW1ksWR9lr621G2NF8q5fLrAPN6mPeCM0pguopVkEaOP9Psp2ySyyZn8fvWIG16s8vDbxAi/ZAMAAAAAOAyTbAAAAAAAh2GSDQAAAADgsMMjJ9ulcwldHp4PZCI879TTjuf4EhGdnPk1i3dH+UYeZVG++D8RUaanhsWVEZ7UVlKr+/QN8M1AltR0Y3GuX+fRyufZWK+XaO8V2MniGbtOYXHnpBLVJ3LKSepYW9TpTzwHuPxPus2T+XxjltpjOrN45xV8gX0iotuP4Zv8fFtVoNrct4fnbX9fw/PsUzy2Rfctu800kdslNpewbAiwJ8wX7+8Z5Hno/1l7vOrTfuLqBJ6d1ycgBzs+b34eiy0piUTyViXyZpuTb20jc7tjXv7EvpBO2I2k8GPuFD62YtV8gyJoOekbxWfdpd+vmF9sYpbJH0/ZogeTOyI2uMri5/WXWb5LRcmGvN3JjXOI7JttQdsQbsbmfTL/mojIQyKfWtzc6oyl7kiM46i44XmqD7/ffQ+/vwgAAAAA4CDDJBsAAAAAwGGYZAMAAAAAOOzwyMm25Bi5vPxPkznZWy49SvUZG+T5uZ+FOrI411up+si1IDsEylmclqfzgGVud5aX579WRpNVn6BYnNR2LUP8xSy+/sMh/Fr671F90n2Hz7+zIjt3sdgn4o61g1WfpCd58qDMKyMiyvDyfHj5Hgfcep1p2xqh+5LrgxIRuUWCrjxHjk+/5xURPlbkuKj7KqvR6wDnmBq+/qynztaoOSeO87hleet4ud1yfW4iIn8FPxFysA8eXzW/P4RMAmuYi1uKbQxEAzyWt6FAqR5soRz+3KIMxCoawJrrbZXPUsMWj8y/JiJKkon3oomthigmxrHc2yOWe/itlX74zLAAAAAAANoITLIBAAAAAByGSTYAAAAAgMMwyQYAAAAAcNhhUfjo8vnVsVhIFxzuK+drnWBfHOVJ+JluXvDmtyTy14vitBFZG1i821LEuKS2kMVpHl4wlevWBW6dfbxo8etQZ9VmVnVPFl965ocsfvHxH6k+/vcO0U1GLMUb7gCv6lFjwFIgu76ebyzjT6CI0bYwvyQLG+Wi+06Jt+mNqNG0kkXCREQmKsZ6MzYwONIY8RrFqX1tVS5xbbIADlpRTH+PSO4wv38U7UnXber5PcVfFv8eEyjjcTjM76MR/XVFyUV87NTm8j7eKttA14Vy0DZ4bJXSqg1//2yF+j6xS1E18ZuK29InKHYyqonxPr068c3UDgf4JRsAAAAAwGGYZAMAAAAAOAyTbAAAAAAAhzmbky3yZF1enuPs8ljm9G5+LBYSOzgkkL9mwk1fwPyhxx5Rx7ZEMlm8M8zjTA/P0SYiior8pi9qM1isFmwnolxvBYsrYpZEOKEylsRi22Yn8rluyv6exW+Unxr3eQ4ZlhzhWJ1t94//x/fNBnVsbU0ei5M9+v0qjTS++4JtAxu5sUz8Uazz3uR7bLuOVG/jf7O/IoFcao8lpzKic9OhcbbcdtUmgQ1DWuMcxq3HrCo5cYtxkcC9GBKQwOtal8nHUmZGqWpTUsPb1GXx70HbncFVzOuXYkGRe5uuv0tj9XGKC9z6HlPZhX9fyTtXc76zwRnuBDajkRvJuBPIsZd53GHS40bWEIVifI44Pm+l6vM+6XqEQwl+yQYAAAAAcBgm2QAAAAAADsMkGwAAAADAYc3OybaurSvyOGXelWl8Sd9mq504TB3bcjbPKbpg8Fcs3hlJU32W1nRjcYZYvzrFrbPcQobnFG2vb8diW052lreKxe1FjrZtTeVt4XbqmCRzxrdG+PNUTtDrb2c+E/e0hwyXyC2W4zFawV8PIqIKkeec6atVbWqiPI9RrvUp86+JdJ62zLe29ZF5cFEXHwelkaDq08HPF8KWuXOuKNa3bi2uFPH+WF56lzhmRHqkZSl+lXPdnPW3jayXsa17Li7GnczzamPV1U1/YtASyG0P7uTfNbtWZas26dvEGtdB/l3ktWwVUduev+9ukW/t36zvMR7xtRcWX53JO/VYqinAfaetcB17NIsz3MtUG1n/Y9svQpL7hsjvOI/RedwecVOU62QfF1yv+rxPg+JeS1uGX7IBAAAAAByGSTYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADmt24aMsKkvoyTrkq2PhQr4ZSMlRvPCiJl8vnD7ojFUsnp73lGqzO8oXMPe5+PVuCetCksHBjSz+qLwfi4u9qaqPLI4ckcI3gCmL6UKSAi/fWOCmteeyOC+oCxSf6DqLxWFLUcGaMC8iKI/xYoZf9vtY9ZlJuerYocrE4hTbWAqO6mP8IxCzFJ3GREGYLFC0CYtF9m0FsJJbFI7I55HXQWQpWBF95MYlVvFeN0iM3OTBsueDegsTeenj7x3RZLIQ0vq0tk2KoFVsO5l/b6Ru1G0yNvJ7ireWf/a9ZbpQP5LJvyNCWfw+5au2FKvV8fNWdfSrNlJpe34eb9fO/Do2bdGdsPlRiygZwOdC79UEVJuqKC9yTnPrBQCkJBcff4lsWCO/00rEwgMjA/ocdWcMZXFg1sK4z9OW4JdsAAAAAACHYZINAAAAAOAwTLIBAAAAABzW7JzsutOHqmPtf8cXEh+UvpXF/ZLnqz6hOLmrK2s7qj41MZ4T9n29zvUuFxt3yIXSi+r1ZjT3bTiVxXOG/ZPFt24/TfVxJ/Okyj1Rnrc9KZVvNPMD/jdf2eUTFnf3F6ke/63uwOLtls1p8nx8Y5Juvt0sPiftO9XncMrJbo7R7daweGVNgWoTEAvzy82CbDnacrw5wfY8lSKXTuZ1N2fjEmgmbwu92DJvO4Ec7XibzxiPPokaK36fagPNECfX2NOnp+pS25fvJBPdqPNo6zP5+1OXxZ8nbT2/NxARiRRYqu7Kr8VXrqcE4TT5W1z8QgJPFe+z/mKek93ldktONnKwW0TxaL55WtRyA5HfLR6xa1bUUg8kc7BjCfxmGxDzO7lp2/OV7VWfkiv4JnIdZqkmbRp+yQYAAAAAcBgm2QAAAAAADsMkGwAAAADAYQnnZLu8vOnwP+m1Ck9J+5bFNUasyRnTOX623OJ9ZXhr1LG6ML+WonC6aiP1Duxk8U/Sl6k2nzwynMWjQteweN1YvR73nFqeB7c7wq/l/A1jVZ8lm3l+2vHdNrB4QNo21UfmmKd5QqqNXAu8OsZf/y9Cep3vw4pl7fB4QiZ+3mmGl68ZKsexLf/aLXJg3SKPUeaiERF5RJsakSSb6tXr3paG+biQ63xHfYkk8DqfP35EknnQlhRTkeqo1s22LNOuJbC2tsrBdicwDmSTbHFvLt4T/xygxck13jJB56Emr+ZxNEm/6X5R7lPThX+O07bpz3VJX/GVL5oEt+lxUtafP3dSET9HXZb++/xlfCDXFvDvJtfgo1Ufs/RbdQwO3OSBi1lcGU1WbWSutEcMjCjpepNE9n6Q/GKOkuPl+dYlUT1Huemo2Sx+hjqrNm0ZfskGAAAAAHAYJtkAAAAAAA7DJBsAAAAAwGGYZAMAAAAAOCzhwsft1w5j8e0Zf1NtXig5nsWdk0pY3NVfrPoMTN7U6POmuXWBX590njz/3+pOqs3csr4s7uArY/GnNT1Un5du/yuLp19/A4tPmHWV6lPRjf87JZLCi0TSB+pioVsHv8tiv6iQKovyYjYioqxANYszPbogVJKFp2nuWtXGthHCkaQ4zDclkhvPEOnNjwKieCNs2fFFFjbKIpFyS/GJ3CQg6OGFjrKokYhoZ6zxot/6zAQK3sARJsALYm1FjJY9HTjb4wkUOjaVK2o5qbi4WFBvgALOqz5aFzSnfMtfe1vhalS+PX5Z6KgHYLzNqVwxPS5cMf7cbnG5yR158RoRUaSS35e8FfyJK3vqArfUpY1fGzTPpEy+SMXXIV04KDejiSbw+2uSi3+nyU3aEiELLrM9eiydnLyDxc8F+7A4VhN/LnQw4ZdsAAAAAACHYZINAAAAAOAwTLIBAAAAAByWcE52cBfP9/pvxSDVpnvybhbLfNf3qwaoPp2SS1mc4eF5wz3FJjJERMtCmSx+b7de2L4gma/UvyucweI94RTVp0Zs3vLvB+5n8X27TlV9fpK1hMUD/TwHuyym/x2zsj6fxZWxJBbbNkgpj8rNaHR+ddjwt9MjNhnJdOvcpYoB2erYkcSWTx2P3HwmlsA5ZM6b3JzGRuZguy2b3sg2cgOiCB9aVsaShwlNZ3xiHFjyq9VQaaWX3h2J/0Rqbwn8BNMi3P15vZBnp1+1kfnWvmrVhGLy2zvCB1wkOf4b6BJ9LLcYMirXmw/iUK2+/lgur1sJ7OQXW5Or75mH+VZprcKbn6eOHevnr/VnNfpLIUvkQkdFfYZH7qJF+rtHzlvkdx4RkVtscpPp4QP75kXnqD5vjniUxbWj+XwvMEtvjNiW4DYKAAAAAOAwTLIBAAAAAByGSTYAAAAAgMMSzslO2yLX7NUJhx8V81yzvKRKFg9K26L6rKnh+clf1xaweIm3i+qT7OHJgxl+vZZ2ipdfb46PX0thoEj1ketVLwzx5/557lzVZ3OkHYvfqe7N4pU1/O8hImrn5bnRX1fwNjURneNWF+VvVSii89szAvx1GJrF1yBfQx1Un90Dj+x/Z6m8sQSWlW7OeqA+sba2zOtO5HlsOW7ycyjrCiJB5Fu3FrlOtr0RD+UwaMbQahZLiqXKyY6k8bHU9OoFsKnuwdeQtr0XoryGovorQa+TLdazVjnbFrFMfl9yRyxj2MsvUNYVeDfpHF/TnX/Hmd38Yup5idQP5+nA5wKRHboeCxpXPrKbOuZx8ZtKjRo4RLlePj+SOdny+4uIKFfUhcm9O+z7R4hrEd9Xo7qvU32C4ntvTz8+RgtmqS5typE9wwIAAAAAaAGYZAMAAAAAOAyTbAAAAAAAh2GSDQAAAADgsIQLH93zlrL41dkjVZvbJr7K4nllvBDyvzt1sV5FPU98zw3yxcnTRcEiEVGWWJk/w6s3WUkSifqlEb75TJ1bF3hERdXbzjpenbEg1kv1Ccd4cn+diGWRJhFRSX0OiwuSy1lcadlBZGNlFouLy/XS/aEgfzvnR3uw+LT8b1Wf5KIEKv0OFebAi/yS1I4c8dkKIeNtNhNI4HliYjzaNqPxunlRSEhUTDVjrx1opmhAvNi24kJZPyQ+fi1VpiqHqKWGltxh/uxlvfi9OXuus9d0pIp5+ZtuWUOA5F5j0WTLeXz8/XLVx99YRg4wf0o9i62Fj/V88NQW8EGcvUTfZLKP55uyrd3F/4CY5b4Ua88XESAUPjbZttP1B3txHX+PqyyFj7JIsV58j3TzFqs+8lsvzc0HbXuPnrt9V883y6mM8XFxQoYufKwR11bVr161acvwSzYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADks4J1vqftPn6tg/VpzL21y9hsWn53+j+iyp4Bu+bBa5x8tr9WYuPjdPNgv6dI5OksiF9nt4rpItZ1bmwKZ4+HnlBjdERFkBnh+e5uEbwtjyaCWPuJavyrupNnlBnt/UM13nSEVE4qXMb3pywwh93r99xg88dH1jl9q2uWSCa/wM1wqR/x70Nz3fy7bovsztDhme62jbWMZ2nn3FLLnfHrGTRV2MP09Cm5uY+GMU4qvqrGspJJUbHWdzGiJLXn0CidvGLfNzxYYiljxgmS8eLLYkbsMBq83mgyDm129o8m4el/azfF8l8WPeSn5e2wY28j3OSOV5tFE/r10iInKH+Hk79+O50mZWe9VnR2Uav1Y/H9gmU48t40MByYHq3k1vstfdy9/0k9LWqDZys5nltV15H8utbfhNN7I481k+J3x+ywLVp8C7kcXrw+mqjdRJzFKH9t7AYl7R1vbgl2wAAAAAAIdhkg0AAAAA4DBMsgEAAAAAHIZJNgAAAACAwxIvfHSLooSYLlzIeP4LFu95nj/+2qTxqs/wWxay+Mxuy1nc179L9fERL6JIslQLpYjCn5AogrP962J+bWcWR0Wrj0qPUn3Kwnwx9V01PJHf54lfPBQTVUi1lg0Bymt55YHHrQthQnP5JjcbVvLNgDJm8dcaNJ/aLUQXE8qiWVsRozwmi1vlxke2NpKtT7xNb7AZTevxhvh7EbPs6yELHdWmHJaCRDm8EnlPPWJjGfk8tgLLcCp/cu9GFD62hFCOeJMt9/LkPfy1L063fM69ovBxJ3+To5aCykApP1ZZIwq/m/Gzm79Sb6xVVRZksSsmNuCp0YO4ujMvugwuavq1HOmKZndSx0p68Q+7m/SHX26olueLX07or2q8YL7GsvBAWazxKadcIICIqDjKPwsLVxeyuDfxjY/aGvySDQAAAADgMEyyAQAAAAAchkk2AAAAAIDDEs/JtuRgN1XK61+qY9+8LmLi+TauoRNUn9p8ngcd2KM3iansytukr+ObxrjrdO5tbPkqdYyrivM4EVEFi3S2WnyWPQQoN6Ge3zXj2Q4jCWw+Iy0u5nn4nTuVqDY1YlcHuWmMbROZVE9do21sfWReXJ3IXwt64ifjynMYTyI7lzT9dQMtbQ6/f5T27q/a1GWKvOda1USRG8e4I/z9knneiajJ18nfMk87adlGFiND2xmRFP6GeWr1exFqJz/r+vvKk8SPucP8PhXzWs6bI+I9/HvSn2IpCsjhG6z1a8c3o/mqVwfVxcTEN5/IO5c52kRE9Wn83hVULSCeghmfqWM9rktlsZtKVZuFdR1ZHG9jNCK9wZU6Z0hvJChr7CpivCagh0/nV/fw8es/6n4+x2rr9yX8kg0AAAAA4DBMsgEAAAAAHIZJNgAAAACAwxLPyT5IzMKv1bEkSzspXacmMY2v8AhHis5pZTz26ZzsoLuexUOT17PYbxlNPpHgmuFueuZYjUjGTbIk375Txddu7+jj+XbBQp6/ZiXXwCdypAbjSBOt4K9150eWqzZlEwewuDaH/84R5ksFExGRSLMnd9SSNxunj1xrO32jHrNZb69ksfx7wBmmew2PN+ns40gCX3JucT+I8vRq8vBUaiIiKljAa0XWT+FjybaMcbu5/GJmu8X+C5af6oIZvNigtobn1aZs0vec7Hd4TQPuQM4YN3k6i2e/+rSl1TYWlcRkZZiuFKtpz99DMfzoxOQdqk97j1gL3VXE4kKRf01ENOL6q1ictvIL1aYtwy/ZAAAAAAAOwyQbAAAAAMBhmGQDAAAAADgMk2wAAAAAAIe1+cJHgIS5REFYApusfPlNDxZ/FSjUjcp9/LS+BMpmxT9fPVXigNxhhEjtKuKKuBp7+IenEXs+1GfwRrmL4hfJocjRIWL8xaqrVZP0F3jRTrp43NshX/WJdG3P4rp2Af60lnGRvIUXLZqNW+NemxoFzfg8QXzdL+IFfiZcrxuJYuRcy2fUPZAXPZuV/LyuPt1Vn9g3q1nce06jl2qV/UQCjR5v+nlxF2oZrgXLWDy+YJBqEzprGIv39ONTw+QTi1WfvDm8sFFulzR81nWqT0ouL/pNfT2NxRnP66LGNDq0Ch0l/JINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMNcxiDRDgAAAADASfglGwAAAADAYZhkAwAAAAA4DJNsAAAAAACHYZINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADsMkGwAAAADAYZhkAwAAAAA4zJtowx+5Jx/4s7lc+pgDu7p7u3ZWx3ac0YnFvS9cw+ItlZm6z/e5LHbX8euNZkRVn4lDlrL4rWWDWNz3Ov68RESxykp1LC752jnwutl8EHu1Rc67L0fGErR5h/RYst2r9uXQ56/27GEsTl25R7WJfreuyed19+/L4qIR7Vic8/jnTT7nwXRIjyVoUzCWwCmJjCX8kg0AAAAA4DBMsgEAAAAAHIZJNgAAAACAwxLOyW6WZuQRezt1ZPGq33RSbSaMXMzidl6ds7irfjeL07whFv+509uqT+ExqY1eW1UspI7NqsljceQYD4tz5+v861VV+Sxe9EVvFvf56wbVJ7JzV6PXBgAOconfH2K6HkPy9O7B4u+uzFVt3j/3Xhb38C1r8qUlhp+3zoRZXHMbj4mIRjzxaxZ3ueOzpj+t26OPJfDaAQAcjvBLNgAAAACAwzDJBgAAAABwGCbZAAAAAAAOwyQbAAAAAMBhLVv4mAD3wKNYfMaL81mcXa4LB9dX5bC4NuJTbcJRXoBTXe9n8WvfDlZ9gil1LI5G+b9B6uv1y+Xz8aKeLlmlLN7s5ZtAEBGlevnznHLichbvHqoLMHf95wQWZ//70NpMAqDNakax3ojl9erYpe3+w+Ist1+12SFOO7eW32NyPdWqz9d1BSxeFeLxmNRVqk+Bl983t0fSWJzn0YWPiy9/kMUrpvHX5edfX6D6tJ+4mh+wvW7y9UUhZOuwbKjk8vD3wkTFe5HIJkvxNmpK9Dxx1J0xVB0LzFrIL+W4/vxpF3/bItcCFq20YVdz7HyTzytzH0pWbTwfL2GxOxhkcaymxpFrwS/ZAAAAAAAOwyQbAAAAAMBhmGQDAAAAADisZXOyE8jJKf0zzw38vIxv6LChIkv1SfJGWBwzOjeoTuRku1z8WmT+NRFRXR1/OSIiB9vr07mEaUG+QY3MD6+L6pe4oi6JxR43z5dM8el8z56XrOHneEPnekdLS9UxABBkLmECOcJHLeaf4xuzv1Jt5of4ZzLTo3P6YobnBma6a1kcMjo//OTkLSw+NbiVxdujuk9ZjOeD53mqWLwraqn7EC9Dmpvf25YOfUn1GfPBRBb7f7RJtVGvbzM2KYMW0pzX3oH3q+Ynw9WxPf35OA710N/RJ/+ef1e6aSOLt4/VubdO5dYesprzeUukjzwm+9hytuM8tysQ0F3q+DgwIwex+Lwn3lN9Ls1YxuIxt0xUbTwfiwOxWKPX1lz4JRsAAAAAwGGYZAMAAAAAOAyTbAAAAAAAh7XqOtne7t3UsQHZO1i8pTqTxUGfXs+1LsIvOytJ51zlJvO8ba+L59tEjP73Rb3In66P8RyxTD/PnyQi6pBUzq8txnOya6N6De+6GH+eXbU8z0zmbBMR5SXxdW/XTB2o2rT/+2fqGAAICeQkllzC16W/L//vLH6vNl318RHPPU5z6XtX2MXvO7KeJEo6j3F9hK/f6iF+/T6XzimXbepErrfM0SYiCovfXGrEveztan4dREQv932BxROn3qDapL/wBT+AHOyma0Z+q+1xE4lYGjZu57UjWNxhPv/O2zYmQ/W5cNoHLF5QwmutftPpCdXnud38eeZ+00e12XpTTxa75y21XDEw8XKnE+jj8iYwVRRrsLv8ep+AWKXY90SsoS/zr4mIaicOY/HDD/6NxRVG53H/s6wji5Ov1nUr8q4Zszy3E/BLNgAAAACAwzDJBgAAAABwGCbZAAAAAAAOwyQbAAAAAMBhrVr4GGmvi4VGZvBivY9ifVmc7tXJ6AWBMhbXxHSCfZa3msVhUfjjdumFx2UBUUwURwbcupDJQ/w8YcNfUtvzyOJIEi/LsspOqk+6V2xaMbpStaG/60MARzpZtJNI8dfCux5l8eI63qe7t0T1WVmfz+JKowuyU1xiIy1R6JhkKWL0i3uMrTgyHtlHFkLa2sh7V7rYnIaIaHU4hcWf3/tP1ebHn/ONICIb+IY1Lp++f5uw3pALWsCwASw0Pj0u6kfx75rvBvPC/LRMvQnaUzNPZXHHufz9nPHxMapP+JTeLA4O1ePCXccLdt2D+rE4tmyl6gNCMwqPEyqYFW1sRYyK2KjK06enavLC3+5n8foI30gryVJg/vTdZ7E44/svVJvW2hQLv2QDAAAAADgMk2wAAAAAAIdhkg0AAAAA4LBWzcnePThFHZP5NCMy1rHYttGCT+Q1Fkd0rvd8sfj98s08z9mzWW/44q3mOToekVLkq9Y5OzJNOxrg5yg7WucyXXvybBYX1fPr751SpPp08Rez+NNgD9UGALR4+YSRD7uoY6vqea3IxjDPtz47pUz1WSnSiGUdCBFRtTrC+Y2u4WgJtrxueSxkeO2ILfdxcySLxUXR7arNjtMKWJz7KM/JNhF9XhCakS/qSdffi+Xjj2JxyjaeZ+8t0SM07+lMFoev2cPiHTvbqT69fv85P2/XziyOWP6epKUbWOw6rq9qs3k8z8eV39Edl6kuILn1fUnmRifC243fNyPt+aZEdbl6jrXrOH5PqWvPn9d49LhYXp/D4k8q+bjonbRT9cmev41fm2rRevBLNgAAAACAwzDJBgAAAABwGCbZAAAAAAAOa9Wc7NxHP1fHnvlwDIvXXpzH4sBR5apPxz/xnCKz8GvLs+1mUU8R2/LVXGk838ukJLM4ls5jIqJoMs8x8lbyJLH2f9frdv6PMll87FKehzkq5TvVZ1uE572dWrBGtVmMfzMBNNmfe7wet02mh+eqelz6syZzmG3k2vsqN9qyBLaHnF+/1ZaTLa9N7gFg+/sy3Xwt8Gy3vkeWDuYZkbmyQQutT3s4kWu9ExGZqMijFa+jqx3PkSUi8oZ4m+KBQRZXnKjHxdrR/2LxiF9dxeJeL1nWIBYim7bEbWM6ie/+Ej0uagr49Z3+Uz6nWP7JQNXH9dnyuM99JHH5LGOpjo8l90Ceux+7X+/L0SmNz6m21fDail90nKf6fFh+NIuvzf2YxVd8P1X1+aC8P4szxJ4hJVFd62csf6MTbJ/DeDArAwAAAABwGCbZAAAAAAAOwyQbAAAAAMBhmGQDAAAAADisVQsfv/vnMH1Q1DZ0mCeKN5bpAsX6dryQ5vxVevMWWbSzLtSexSsrdIHOtkpe+FgXEQWWlo0iXC6+mH9eWhWLL+3EN14gInqt6FgWL7mMF3wsK9cbzZjtu1gcq6lRbcABLkvlmSQLjJpTlOTz6z7henUsLrmxQDM2FbBxBQIsNvXi2g6jYrWdEV0glunnRT266E+/zvKeUxnT95g0Ny/aqY7x1zlJ7m5FuiCxXmxy43Hp+5LcxCveOWxS3LyIe080VbWRBaE7ovq+9J9TeeHc3TQo7nMDp+4nRHE/g6ZKbywjhgFVncTfr4KX+HgkIho/dRCL0yh+oWNz1OXxArb6dH0vbr+Yf/fPqj+BxflJYncaIkrqWKCOHclMnX6NpNjyVSz2XqRfw43basURHv+delvOzO9vV9MoFs/Y8Jrqkevh3z33FvHFMl6cdZLqU7iWF8Qm8h2t2liK25vzHY1fsgEAAAAAHIZJNgAAAACAwzDJBgAAAABwWKvmZHf8UOdYbefpNVQ8kef1zDhObxRxw7sXsviZW89Sbeoy+L8fKkSacyTFks8mDhkvP2B8uo+rnv9N1TGe3/nXV85XffyV/DylN/HcuUg4U/WJlfGc8pvHvqPavDX2GH6eHTtVG4ijObnGltwtMhF9bN+Hm5HbtfWWEerYw5c+xuIZPQY0+bw2ieTtHapiJw5m8dDAfNXm+wjPP8718M0YymP6/c318jzn3RFdT+Jz8X4y19tjqfsIG36blhvJyHxrIqKoOBYTv6e4ST+PzO2W+eK23O8B/goWl8X0Pb4mpvN8oYmacV+K7ilRx5Lf+orFhW/FP487LY3FsSped5TQtclaF0ufqgL+WQiU6jb+Mp7T2+VtPv5qu/BrJSKq650f//qgUZFt2/VBUQ8kN7lpznfIL1bpzWjmDXyRxWsr+XZWvU/YqPrIyhYTafz7ONE23mbk9+OXbAAAAAAAh2GSDQAAAADgMEyyAQAAAAAchkk2AAAAAIDDWrXw8aTffa6OVUV5Uczi4s4sfnI7X6yciOiiMZ+w+A8/XRn3uatifNOYEkvhUsjw4oyoiGuMfrmSxKYPGW4ed/LqDRy+refFnb/bdDaLvy/O0c+zIonFj6w/W7XpsOMzdQwcEKdopzlFjEW/0EWMZQP4mLx37Ess3hnZo/osqunO4uJ3+AYAOWd91+RrIyJyJ/Hx9v2dvFiwx436s3yoiPn4bwtJlsJVWUzY2cuLeOqMLvDziMrpNI/crEG38Yv7h3yciIhEsaRbXJutIFGepz6B2jS5gY3aKMelN8qpjvEThyz3yNOC/LV7IP6lQAuRG26oDTk88Tcpkm0SKRhLRG0u/0z5qiyDVn5UPbxPfZq+fnfk8Nk466CxbdImirQTKXSUm7DJ707zIi9qJCIKDOIFsV43f95z8xapPi+mHcXiWGWlaqMczxeOyHtgo2qyfJfeuCwe/JINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMNaNSf71dkj1bFjR61h8Y09ZrP4119NVn3WvcfzUJ/JPUm1SdnK//1gRKpWzPKXR5NFrm389DRyRXiuklekYbp1GiOFRZp2qDPPS1p7+uOqz8UFo1n8TNdPVJtTF1/CYs/cJfrJgUtgk4R4my24Bh+tjq07n29E0v24LSye2+c+1ee5Cp5PPbuMn3dLdTvV5/T237L4lWOeZPHVpGsaErH9yiEs7jFkc7PO0xYVHcdzjVPderMUueGLT4yT8pgeEzsjPF+vm69YtamIJaljjT0vUfyNZWxp3B6RXy372PKrbcf2JTfSISLK8/Acy/V1yarN5kg5i+vHH8di//s6pxJaRrz8advjRuSzyrxuq0Tuq0IkyOMRk5epNh/PGcTink/za/NX8nFPROStdiZn/IjWnE3abKeJ6vdnX5nP6lqfFXfyerpuKbw26btQB9WndCL/7kzbpPPFL33iTXFkE4sGBPQGPL+5YAo/MEE1UfBLNgAAAACAwzDJBgAAAABwGCbZAAAAAAAOa9Wc7OQ+ZepYaYgnYn0q8lJTFuocv9rh1Sz+cS+9TrZc5zZgS44WwiIJW57DbVmP1u3iuUoBN8//isT0v2OWlPC1wCteK2DxXUP7qz5fbenK4gE7p6o2nZesZXHj2U+HGLdMqtd/nVzbORYKqTZKArlmnrz2LF5zb0cWvz7qn6rPtijPz51bwdft/M32sapPqofnjeX6q1j88fpeqk9NDs+JPePZG1ncjXSOm7crH38bLuqs2iy68kEWT/rxNBbXjz1Wn/ejxepYWySXuPa5dPFFWKz3XGnJwY7Hdr+ojPH7WbaHv8f1lkKQJHHvkvcpub61lbh8W+53tpuPv9VRfm/u4i1VfQIuvoatXFubiCjLzV/Liv+rYHHO+/pyjyjWNYjb7trOMm87kRztRNbSThLbAHywsp9qkzeoiB8o4znZZT35vZqIqMO8KnUM4mhGTr3qY9l/QK6tnYj/VQ5gcffk3SwekMTrnYiI7prxNYujluf9QqRpy3vzz9foOVby+g2NXqsNfskGAAAAAHAYJtkAAAAAAA7DJBsAAAAAwGGYZAMAAAAAOKxVCx9P6rheHUv28I1YTstYweLPdw5TfSpqebFNbdSv2myr4YVnXjdPfK+L6D/d5+EFRLJo0ciKKSJyicLHnCRelFkT4ddKRHR05k4WL6zhhY+FAVHcQUT98nmfHql6o4tvuvXhB1ZUqDaHDFFE4XLz2FY/kVCho1B97nAW7zi7XrX534mPsHhJqBOL/16kixhro/x97xbkVT3HpG5VfYrCfAObnXU8vqjfV6rPl6XdWDz1rHksHj+VF4AQEe2M8gLZRzePVm1+0uUEFntSt7E4qYx/voiIDpUtH3wJ1EHJjVfKY/z9rDC6wE8WOvopfpGP7OOxFCQ6wS2uRRb5EBEFXXzTGLmBTZZHF49/F+b3TL9Ln7csxl/LtID+jB3R2nCRYyISKWqUYicPVsdyl9awOO+f36g2JRcOZfHOn/BCR8tUgGhN04vVjnhOjEnL4gTN8dGAFBaf+g0vdj0lWT/PkD/+nMXhdH1f/duVfMGCzt4yFu+Zqze56UQofAQAAAAAOOgwyQYAAAAAcBgm2QAAAAAADmvVnGyvW+fOlNTzfJuQ4bmP/grdx5fMcwMjRv9bwS+ey+/heWNuuTuD5foiYpMK2+YSEbkxhDhHqk/3kRvjBHfHz2nrm7aL9/HovMaaLjyHN2mFanLoEDlhzcn72/z7ESz+v/PfUW1ODD7EYrnwPRHRg0WnsFjmWw9P17UGktzcRG50RKQ3FYnE+NhaVs5zwYmIuqToDUL2dfPaSepYYNxGcUTnh6/7K8/JfuKcx1j8Ttkg1WflpXrziLZo2tWzWFwV07n81bEsFme7eb7oQH+t6iM3iZEbVR1MfjG2SqK6VkRmXGeJjXLSLJtLrI+msjjfo+tAtkd5/vrc/m+yeLxL5+ce6nnKhzO5+Uwi9+YNf+b3k3A7/b3e9xE+drZfo+uxkvbwcZH/6hoWR/p2UX2aU6sDCYizYY3LpxPkTUTcZeTn3LIx0+tb+IZqa8O8zfgCXldFRJRr2YRNKrucb7aV5OLX1u3ZTapPc+qO8Es2AAAAAIDDMMkGAAAAAHAYJtkAAAAAAA5r1ZxsmXNKpPMWZe5qoFjnUyUl88yYsMhdJdL51THLGteSbBMTa9ba/kVSK9bBDvv4tSRb1paVa3YnbeXrPhZHeG41EVFdTLwubp0dVJ/OrzDJcr1tUXTMEHVs8ziex+npyfNDky1r7Q5sv53FQ5M+ZfGamnzVZ15JbxYXpuxRbTK9PB+3ZzK/lqhlZOyoz2RxmoePY1t+f0isxSzHTtiSx11cx3NiS+p5ntltPXQeumcd/8x19eo82lnV/HV4djfPb88L6D6rr0pVx9qi89L4+rslluWss0U+slwjemZVd9WnwMvz4z2Wuo9oC62D3VS28Vcm7jHdfCUsDrp1Hrf8ewKWe3xQrDn+elU2b4D860OKzMH2HN1Htdn0Rz6Wkj1lLA4X81osIqL157djccZay+dHDMFYId9jwl2nvxcPq9El94/wiLmPpW5CMlHL+tUOrWkd93nifNaHLtXv30Xrz2Jx9Um7m3wt7iQ9G5I52DPLj2VxZCvfG6K58Es2AAAAAIDDMMkGAAAAAHAYJtkAAAAAAA7DJBsAAAAAwGGtWvhoIwv46sWGDt7NRapPWpIumohHFljaNrBJEsWSXhKxWxcLeUQBUb0owrQVKEquUJ24Vv088rllISQRUczTNoqq4tlyKy+iG3LGStWmf4AXnnmI//0VkWTVJ8XLX8dddbyA1Pa6FiSXszgS0+NiS4gX5Kw1uSxOshS3yo1ksvy8eNJ2Le18vI3ctCjXr58n21fNYllg+X2dLvaUGz59bSkNqonxjQRyxPvRLalY9WmrPL14kWIH7zIWL67TRbQFHv5eyKLAeqM/f3LDF1uhqm7jEbE+b4qLX588h418j+V91XaOkigvmu3j48WtlZbiqN2R9izu5StXbarFZ+pMUVz8OOki0kOV3KiFqHkbabUUdX2iUM6drAvEohWiyHkY37Ardg8vkCUiqlnfgcX5HXlRcP7lq/XFJVAAGzuZb1xU3psXW7ebozcGc76krxksm6zE3YjF9no4sElbq0mgmLL6Pf7Zf2NtULXpfO436hjj1gtfyOd2+fXGOAVefq96Y9UgFnenZY0/b4LwSzYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADmvVnOxENoSRGzhEdu5SbZK8XeKeV+bEyhzYuqj+072ijdyMJhaN/2+SkFgtX56TSOcXmxSeB/edZdMUuSGKTfQQ2X2m22Pfs3jbwp6qzaKRYteBvjwneFBHvVB812Se69kvyDenSXHznG0ivQGMz6Vz3Iam8vyu4UlbWBy2bDCSJGoAMkTeWNClc8R8Lktu2T42R6rUsS0RnsNWFuNxdYxv6kNEFBO5wrstmx9liJzkbXWZLC6N6LqIzv8TB65QTQ6KnafmNfp4yJIHnSlqKcoj/D0uDqepPoOSNrG4wujXPipee5mDnchmNS21oY0cO9ujPL9f5o8TEXX385qZoCX3dLfcYMylN7U5XCSUI2vLz1UnapktVOT1yRxtlX9NuqZh7a/EJm3z+fcxEVHusbxmI/30dU26zv0SX6eyDsmU6+tvE2zvZyI52E3kGjpAHVtzKa9f6nf3dtUmsmVr4ydOIO/ZncK/E2LVvF6IiOj7vw1n8Y+yVrB442m1jV+HTQK537aNcZJEXYpro67zUhL57Ar4JRsAAAAAwGGYZAMAAAAAOAyTbAAAAAAAhx30dbKbI8PP83Zsa17LHGy5zrRc39pG5Xpb0nFkjmXM8PNWRXRepk+sxx1N4fm5czfpHOWpvRexuNyyTnQCKe9tg5tfaPKX36smXd/X6+3uqzyo19Ocf/RQFpf25WuoVnbVL1CoA38vTMCS3yW7uUXuXEyf17tH5OZX8zYBvbQsBcr4eZPK+LUESvR6zp4qscZ6ZfycNpMk8sETyTPbznNv15Tp3NNk81X88xwEbr28OLMnmqqO+fz8tZbr7PdL1jUBfpEwWmnJYZY5/4msX+0Tx6pjyY0+biPPGyP9opSJdbJ3R9MafZyIaGCAvw5JlrqCaqPrD45oLZRvrSSwNnMiOeRr7+Sfj+hOPg58R+s86HY/1vd0J7hi/PpDOaJuKsTrCA4WV4B/77ss74WJitqsML/nyPxlIqJnf/woi+dVHSVa6Hvw3zMWs3juyXp+8cpRug6MseU9i79J5mB7+ujn+d2pb7H4tfPHiBarVB93Gr8PxSorRYME8sXzclUTuY9BwfxE6ima/rs0fskGAAAAAHAYJtkAAAAAAA7DJBsAAAAAwGGYZAMAAAAAOKxVCx+31LZTx/KTeNGEbTMQKTvAN8qotBQXyg03IvHrHNXmM7LYyU26YEUWMcpiydqI3nhBnseIQsC6rboQK9iXF0WUGl2EZKmzapOiu3gRnSczQ7Xxdu/GYvka2biLylicvZYvsJ+TYnnN6nQxoeTyihdWFi559AtvgmJnIHEOE9DjIubnbaJB3qY+XfeJ5POxX5+Wyc9p2fdDFgLGLHeBSJC/3r7KLBZ7wvqzkL6hbRQdSXnvbeYH/sjDmOW3hrAoYA6Z+JsWVYs2toLKJBd/8eVzB9160ym5aYK8FrmBF1H8gkp5HTbybwxaNnNKEwXlNZaiPnkvVjuKHE4SKDb05LVncawzj4mIqjvzjT2CM79s+rU0o8By7YPHq2OuKH/fO/fbyeLAuI1Nfh6XL34xrCwEJCIyXv76hrJbqYi0iUwdf82ac5V9+29Rx0Ym8c9SlNaw2E+6QHFBbTcWH5+8QbV5/KKfsDjzmc/jX2Cc8dXtOb3BzV1f/JjFvZcvVm0kVejYDHVdstSxbWITtsCshQf8PDb4JRsAAAAAwGGYZAMAAAAAOAyTbAAAAAAAh7VoTrY7ieelqs1dSG+ksLYuzqLoRJTi5flO1ZH4+V0yLzDo1fle9SI5VeZk2yR5eG6jPEc0pv8dI3O/jY+3Sdms+6R6eL5rnSXZNuY7VHaj4aJllo1nbMfikIvWuwJiXNg2XsjkfUyyHksxf+MfE+PV75fMIXclUBRgPPw8LpHz5i/TYza4UeTwuuTYsuSLy7/Hdm3ybxJt3JU6dzi6Vuf6tQVbz+3a6OO2TVbKYvzvHSZy6BeE9N9fFuPnsW0skyLymuVmViHL57pM5DD7RN5l1LJLVpJIvJe5mrY+aR6+kdFukbMoz0lElCTGW8iSpynzww/rnOwE8qBrjuXjsaKLvr8EKkQed3q6ahOt0JvANJWnV3cWH3uc3kSmnZ+P9Y3D4m94FZfRY8BE42+qJIdOuFP8mpqDoXbiMBbb3uMOTy5nsdzMZUT2+rjPs7qugMXfVHdUbYrreG3I1rRs1eb6373E4qeeafyeaRP5sAuLr8l9SbXZdCvPjU5g+xdH1LXT99XtEV0jGI8rgdowCb9kAwAAAAA4DJNsAAAAAACHYZINAAAAAOCwFs3JNiI/zZaTnSxymj/Z00u02KX6BNw8k0fmOBMRRdTarJzb0ifeuti2c0ai/CX0inVjbX+zzLusz+DnyFqjcx9lLqftb7Y81RFFraeZyPKaO+M3aY7mvBWyTyLnSCCLsUUcrOdtDu8pxY0+XhlNVsdKYjw3v1A8ft1dv1B93r79ryzOcOv8/g0R/sqFxT2lLKavRa6LLXO9bfnVsgalXjTJduu82lyRk907yNdqvnjziarP2V0+ZfGqep2rHo+3Wxd1LLJxs6VlC5NrXDdjnelE1smW6/HmJnDaFvu8Pc5rfS7M0+sjPzL9pyx20bIDflpjq4+xvXaySYy/lkN6bGLxga+o7Izy7vw7/ZMb7lNtPrwmj8Wb6nNYfGrqStVns3jdqqK87u3MzGWqz7ggn0/UGT2/CLj4Pea3/5zM4j7/4vniREShP/NjT/V6jsU/W3WR6pOyLX6eeUuo6qBrk9aG8iwtG2diTb8n4JdsAAAAAACHYZINAAAAAOAwTLIBAAAAAByGSTYAAAAAgMNatPBRksU4RHozmtW72rO4q6XwUfaxFRfKzWa8Ll6QGPDowotwTCfH78vt0gvoqwIjcY5ENrQJZfA+2cvKVBufi1+vLMokouZV2wEc5pJ9/LOzIVzF4s7+PapPWG2gwmU9qQvERgz9FYsf+dEzqk13bwmLBwUCLJ5Tqz/E2e7GiwnrLb+VyPtSRYwXSBX69SYedaJA74YdQ1j8zeP99ZPfxQsfw5ZrkYWbRLzwavNPO6k+BTMOQuFjcwodm3MOUeAXmKsLsE7M5pvCvPDoeNWm/d8/a9q1EdG6+45n8aref2dx7/9dqfr0XrCoyc/TUoyXv3a9U4tYvLiN/G6Y/wB/b343dbRq88v2H7F4QGAHi0OWe9Dcmm4s7iTuXf38parP4jpegJ3r0Z99N/GFFTZMeJw3mKC60Fd1/HO8SxSQB+/UGyjpJxZ/Y6xlSnzrM/SxtdWy5LhEN5KacX1tY0QCAAAAABxGMMkGAAAAAHAYJtkAAAAAAA5r3ZxsS9KwzK8Ob01RbaSycJDFa0tyVJvKKp4fFIvGT1g2UfFvDjfPr3PZ8qvFaeV6+j6/zv3O9PMcy3Cq6LRW5yN6RA623MSCiCjWqu8mwKFBfmoLfaksXhm2bIzRDL1//hWLH6a+TT6HO0Xf/9xZ7cQBcb+wbZAgcoNNiG86cl+xzkPXeA1KFuk8dLqLh/I+RaQ30iqK8k0s8sdv0eedkcDlOazmJ8NZ7KnTNTj+cp6H6i2q4A0qeL4/EZGp4Zv8xKp4m4o6ni9PRHRh+nIWl18eVG2W/rcbiyOb+OtYeR7PvyYieu2ch1h88Sae6933/75RffSr0EISyGc3YuyXReTrEqK2aMF2uZ0V0QMF/H1/t4YnDqdZNow6MXkji33iVrBJvR5EWW7+mkRtL7M4z4p63qckqs9LxOtJ5lf35qdcsMzSRzAHPrrcKfra5MZ04Qz9R68p5vV/7UVOtu1eHKvWm/LEvb4m9wAAAAAAgEZhkg0AAAAA4DBMsgEAAAAAHIZJNgAAAACAw1q0VM4lqgCtG6gIvqr4BYqZPl44GPSHVZv6JP6ndcosY3FdVP/p9VG+MHoie7vIzWY8bp7IX1ylk+c7JPFimS/z+TlsyfWZHn4s2aP/5pjc8wEAKGOaKEZbysOOnnLVxyc2nqozrVNVbPvsN6fYprW8UsWLtUYk6cK/b+t5oWm2m9+7Nn2lN6MpJEsxZAur6Mbv/1VdLN8AObxINiWNF3+Fw/p+HyoVhY0xfl7Xdr3Bxcl7fsFi77f6vIEzeVw+nG+uMaa3LmK8Yd1kFvt/zd+bWGil6uMO8sKyWE3jmyO1JE81Hzuz5w1icQ/6ohWvJnG5M3Rxq+9VPt5OD/KNZNyW30A3ixrtNWH++SuL6nES9vDPZJpbF4emic+kT5S7Jrn0fKOrlxdm3nb7ySwO0peqT0tsPiPnmTbRgJ57lhXzsd9ePO7yNL4hWaLwSzYAAAAAgMMwyQYAAAAAcBgm2QAAAAAADmvZREMfTxKujvhVk5oYP2YSSIR++b1RLI6k67yeQDHPp9ngSWexK4FUICNScqzXJjejEWuruyK606sVQ1jcaXH8i6mO8dy/esvOM5b9aQCOeNFdRSw+4xSel3rdO2+qPr18PD9y6MJLWNyBVjlzcSJH0ZYH6PLwD7ZJYNMO6wY1+54jarnnyPxImetoed5bFp7D4hUnP6ba9PDtZvGP1/yExYW/tWxycxDkP/DZAZ/D27FAHavvnsfiUC7/zqvsxO/tRETGxY9Vd9abdiQN42O0dyrPvf304wGqT8+n+XsRXaNzsKWDmYMtearrWfzWuY+z+Fe/PqE1Lydhto1ZxhcMYnHFFL550Em/0fnlf8nj5+nhk59jsTmSlZ6H2Y817vItfCOj4BuWHOxWYL2XCYOPW6uOrSrKs7Tc57yJ3GcTgGkZAAAAAIDDMMkGAAAAAHAYJtkAAAAAAA5r0Zxsdypfs9EjE5aJyCeSo8MZuo3U/ea2kcPXmmLi30O2NcfDGc7kEAEczqKrvmdxpkfnnBb6+Bqqg/K2sXiX5byeTL5mbbRMr7+tiDxoY1k31uglaluFy8traky4XrVJ+jqZxVUn2dbT5XH5vzqzOJ34a3soi2zbro65xbGgeFzGzSXv/oWW1/XAVyU+uKLfrmHxWW9fx+JetrWZDxHpL/Ic7GUv6jbjaRCLXccezeJdw/k9iIiorD9fXDu1g17LvmMGv1cZUYC2bleO6tNj6jJ9geziLEVsDqyLrU6ZQM3Ajod7qGNdV+xhsbwyU1tLTsAv2QAAAAAADsMkGwAAAADAYZhkAwAAAAA4DJNsAAAAAACHtWjhY2THThZ/t26oarN2R3sW5y5MYN5vS6iXHFpIvK341fsXsLhd11LVJmfZ4fU3A7QIcf+4/KFrVZOkEv5ZSt3Gi/68tFj1iVU7UyjTZpj4RehJu/nrtDOqN9MpiyWx2FL/DtAsvX556BY6OsEs/pbF7fVtidrrQ/o8cR7vQVsTvqb/d9JWmo8k8Dypr+pxEq8E00QicVokBr9kAwAAAAA4DJNsAAAAAACHYZINAAAAAOAwlzGHWfIyAAAAAMBBhl+yAQAAAAAchkk2AAAAAIDDMMkGAAAAAHAYJtkAAAAAAA7DJBsAAAAAwGGYZAMAAAAAOAyTbAAAAAAAh2GSDQAAAADgMEyyAQAAAAAc9v8BPj4/oakkfzkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 750x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_images(images, title, epoch, max_cols=10, cmap='gray_r'):\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = [img.detach().cpu() for img in images]\n",
    "    elif isinstance(images, list):\n",
    "        images = [img.detach().cpu() if isinstance(img, torch.Tensor) else img for img in images]\n",
    "    else:\n",
    "        raise TypeError(\"Images should be a list or a torch.Tensor\")\n",
    "\n",
    "    print(f\"Plotting {len(images)} images.\")\n",
    "    n_images = len(images)\n",
    "    if n_images == 0:\n",
    "        print(\"No images to plot.\")\n",
    "        return\n",
    "    \n",
    "    if n_images <= 5:\n",
    "        n_cols = n_images\n",
    "    elif n_images <= 10:\n",
    "        n_cols = 5\n",
    "    else:\n",
    "        n_cols = min(max_cols, n_images)\n",
    "    n_rows = math.ceil(n_images / n_cols)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.5, n_rows * 1.5))\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1 or n_cols == 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axes[i]\n",
    "        img = images[i].squeeze()\n",
    "        ax.imshow(img, cmap=cmap, interpolation='nearest')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Turn off any unused subplots\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(f'Epoch {epoch} - {title}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)  # Adjust to make room for suptitle\n",
    "    plt.savefig(f'{folder}/{title.replace(\" \", \"_\").lower()}_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "# Load a small subset of the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data, target = self.dataset[index]\n",
    "        return index, data, target\n",
    "\n",
    "indexed_train_dataset = IndexedDataset(train_dataset)\n",
    "indexed_test_dataset = IndexedDataset(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(indexed_train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(indexed_test_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "print('Train dataset:', len(indexed_train_dataset))\n",
    "print('Test dataset:', len(indexed_test_dataset))\n",
    "\n",
    "# print shape of an image\n",
    "print('Image shape:', train_dataset[0][0].shape)\n",
    "# print total number of pixels in an image\n",
    "print('Image size:', train_dataset[0][0].numel())\n",
    "\n",
    "all_labels = torch.tensor([label for _, _, label in indexed_train_dataset], device=device)\n",
    "\n",
    "# Plot some images\n",
    "plot_images([train_dataset[i][0] for i in range(10)], 'Fashion MNIST samples', 0, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_feature_mapping(x, B):\n",
    "    if B is None:\n",
    "        return x\n",
    "    else:\n",
    "        B = B.to(x.device)\n",
    "        x_proj = (2. * np.pi * x) @ B.T\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, fourier_dim=None, scale=1.0, dropout=0.1, batch_norm=False):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        \n",
    "        # Create the random Fourier feature matrix\n",
    "        self.B = None\n",
    "        if fourier_dim:\n",
    "            self.B = torch.randn(fourier_dim, latent_dim) * scale\n",
    "\n",
    "        # Linear layers construction\n",
    "        layers = [nn.Linear(2 * fourier_dim if fourier_dim else latent_dim, 128)]\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(128))\n",
    "        layers += [\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 128 * 7 * 7)\n",
    "        ]\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(128 * 7 * 7))\n",
    "        layers += [\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        ]\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(*layers)\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(128, 7, 7))\n",
    "\n",
    "        # Convolutional layers construction\n",
    "        conv_layers = [\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "        ]\n",
    "        if batch_norm:\n",
    "            conv_layers.append(nn.BatchNorm2d(64))\n",
    "        conv_layers += [\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1)\n",
    "        ]\n",
    "        if batch_norm:\n",
    "            conv_layers.append(nn.BatchNorm2d(32))\n",
    "        conv_layers += [\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "\n",
    "        self.conv_layers = nn.Sequential(*conv_layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply Fourier feature mapping if B is defined\n",
    "        if self.B is not None:\n",
    "            x = fourier_feature_mapping(x, self.B)\n",
    "        \n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.conv_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot function\n",
    "def plot_loss(gmm_train_losses, gmm_test_losses, recon_train_losses, recon_test_losses, epoch):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # GMM Loss Plot\n",
    "    axes[0].plot(gmm_train_losses, label='Train Loss', color='red')\n",
    "    axes[0].plot(gmm_test_losses, label='Test Loss', color='green')\n",
    "    axes[0].set_title('GMM Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Reconstruction Loss Plot\n",
    "    axes[1].plot(recon_train_losses, label='Train Loss', color='red')\n",
    "    axes[1].plot(recon_test_losses, label='Test Loss', color='green')\n",
    "    axes[1].set_title('Reconstruction Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Total Loss Plot\n",
    "    total_train_losses = [gmm_train_losses[i] + recon_train_losses[i] for i in range(len(gmm_train_losses))]\n",
    "    total_test_losses = [gmm_test_losses[i] + recon_test_losses[i] for i in range(len(gmm_test_losses))]\n",
    "    axes[2].plot(total_train_losses, label='Train Loss', color='red')\n",
    "    axes[2].plot(total_test_losses, label='Test Loss', color='green')\n",
    "    axes[2].set_title('Total Loss')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Loss')\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.suptitle(f'Losses at Epoch {epoch}', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder}/losses_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_latent_space_visualizations(representations, labels, n_features, epoch, fraction=0.05, s=1, alpha=1, perplexity=20, gmm_means=None):\n",
    "    n_samples = int(fraction * representations.shape[0])\n",
    "    subset_indices = torch.randperm(representations.shape[0])[:n_samples]\n",
    "    representations_subset = representations[subset_indices].cpu().numpy()\n",
    "    labels_subset = labels[subset_indices].cpu().numpy()\n",
    "    \n",
    "    color_codes = ['#a50026', '#d73027', '#f46d43', '#fdae61', '#fee08b',\n",
    "                   '#d9ef8b', '#a6d96a', '#66bd63', '#1a9850', '#006837']\n",
    "    loc = 'upper right'\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    if n_features == 2:\n",
    "        # Plot first vs second component directly\n",
    "        axes[0, 0].set_title('Latent Space (First vs Second Component)')\n",
    "        for digit in range(10):\n",
    "            digit_mask = labels_subset == digit\n",
    "            axes[0, 0].scatter(representations_subset[digit_mask, 0], representations_subset[digit_mask, 1],\n",
    "                               color=color_codes[digit], alpha=alpha, label=f'{digit}', s=s)\n",
    "        if gmm_means is not None:\n",
    "            axes[0, 0].scatter(gmm_means[:, 0], gmm_means[:, 1], marker='x', color='black', s=70, label='GMM Means')\n",
    "        axes[0, 0].legend(loc=loc)\n",
    "    else:\n",
    "        # PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        representations_pca = pca.fit_transform(representations_subset)\n",
    "        axes[0, 0].set_title('PCA')\n",
    "        for digit in range(10):\n",
    "            digit_mask = labels_subset == digit\n",
    "            axes[0, 0].scatter(representations_pca[digit_mask, 0], representations_pca[digit_mask, 1],\n",
    "                               color=color_codes[digit], alpha=alpha, label=f'{digit}', s=s)\n",
    "        if gmm_means is not None:\n",
    "            gmm_means_pca = pca.transform(gmm_means)\n",
    "            axes[0, 0].scatter(gmm_means_pca[:, 0], gmm_means_pca[:, 1], marker='x', color='black', s=70, label='GMM Means')\n",
    "        axes[0, 0].legend(loc=loc)\n",
    "\n",
    "    # Kernel PCA\n",
    "    kpca = KernelPCA(n_components=2, kernel='rbf')\n",
    "    representations_kpca = kpca.fit_transform(representations_subset)\n",
    "    for digit in range(10):\n",
    "        digit_mask = labels_subset == digit\n",
    "        axes[0, 1].scatter(representations_kpca[digit_mask, 0], representations_kpca[digit_mask, 1], \n",
    "                          color=color_codes[digit], alpha=alpha, label=f'{digit}', s=s)\n",
    "    axes[0, 1].set_title('Kernel PCA')\n",
    "    axes[0, 1].legend(loc=loc)\n",
    "    \n",
    "    # t-SNE\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity)\n",
    "    representations_tsne = tsne.fit_transform(representations_subset)\n",
    "    for digit in range(10):\n",
    "        digit_mask = labels_subset == digit\n",
    "        axes[1,0].scatter(representations_tsne[digit_mask, 0], representations_tsne[digit_mask, 1], \n",
    "                          color=color_codes[digit], alpha=alpha, label=f'{digit}', s=s)\n",
    "    axes[1,0].set_title('t-SNE')\n",
    "    axes[1,0].legend(loc=loc)\n",
    "    \n",
    "    # UMAP\n",
    "    umap_model = umap.UMAP(n_components=2)\n",
    "    representations_umap = umap_model.fit_transform(representations_subset)\n",
    "    for digit in range(10):\n",
    "        digit_mask = labels_subset == digit\n",
    "        axes[1,1].scatter(representations_umap[digit_mask, 0], representations_umap[digit_mask, 1], \n",
    "                          color=color_codes[digit], alpha=alpha, label=f'{digit}', s=s)\n",
    "    axes[1,1].set_title('UMAP')\n",
    "    axes[1,1].legend(loc=loc)\n",
    "    \n",
    "    plt.suptitle(f'Latent Space Visualizations at Epoch {epoch}', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder}/latent_space_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "def select_random_images(data_loader, device, num_images=10):\n",
    "    images = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "    for batch_indices, x, batch_labels in data_loader:\n",
    "        for idx, img, label in zip(batch_indices, x, batch_labels):\n",
    "            images.append(img.to(device))\n",
    "            labels.append(label.to(device))\n",
    "            indices.append(idx.to(device))\n",
    "            if len(images) == num_images:\n",
    "                break\n",
    "        if len(images) == num_images:\n",
    "            break\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.stack(labels)\n",
    "    indices = torch.stack(indices)\n",
    "    return images, labels, indices\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_images(images, title, epoch, max_cols=10, cmap='gray_r'):\n",
    "    if isinstance(images, torch.Tensor):\n",
    "        images = [img.detach().cpu() for img in images]\n",
    "    elif isinstance(images, list):\n",
    "        images = [img.detach().cpu() if isinstance(img, torch.Tensor) else img for img in images]\n",
    "    else:\n",
    "        raise TypeError(\"Images should be a list or a torch.Tensor\")\n",
    "\n",
    "    print(f\"Plotting {len(images)} images.\")\n",
    "    n_images = len(images)\n",
    "    if n_images == 0:\n",
    "        print(\"No images to plot.\")\n",
    "        return\n",
    "    \n",
    "    if n_images <= 5:\n",
    "        n_cols = n_images\n",
    "    elif n_images <= 10:\n",
    "        n_cols = 5\n",
    "    else:\n",
    "        n_cols = min(max_cols, n_images)\n",
    "    n_rows = math.ceil(n_images / n_cols)\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 1.5, n_rows * 1.5))\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1 or n_cols == 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i in range(n_images):\n",
    "        ax = axes[i]\n",
    "        img = images[i].squeeze()\n",
    "        ax.imshow(img, cmap=cmap, interpolation='nearest')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Turn off any unused subplots\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.suptitle(f'Epoch {epoch} - {title}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)  # Adjust to make room for suptitle\n",
    "    plt.savefig(f'{folder}/{title.replace(\" \", \"_\").lower()}_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_gmm_results(X, gmm, epoch):\n",
    "    X = X.detach().cpu().numpy()\n",
    "    log_probs = gmm.score_samples(torch.from_numpy(X).to(gmm.device)).cpu().numpy()\n",
    "    y_pred = gmm.predict(torch.from_numpy(X).to(gmm.device)).cpu().numpy()\n",
    "    \n",
    "    n_components = gmm.n_components\n",
    "    cmap = plt.get_cmap('tab20', n_components)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Plot 1: Per-Sample Log Likelihood\n",
    "    scatter = axs[0].scatter(X[:, 0], X[:, 1], c=log_probs, cmap='viridis', s=1, alpha=0.2)\n",
    "    axs[0].set_title('Per-Sample Log-Likelihood')\n",
    "    axs[0].set_xlabel('Feature 1')\n",
    "    axs[0].set_ylabel('Feature 2')\n",
    "    cbar = fig.colorbar(scatter, ax=axs[0])\n",
    "    cbar.set_label('Log-Likelihood')\n",
    "    \n",
    "    # Plot 2: Predicted Cluster Labels\n",
    "    scatter = axs[1].scatter(X[:, 0], X[:, 1], c=y_pred, cmap=cmap, s=1, alpha=0.2)\n",
    "    axs[1].set_title('Predicted Cluster Labels')\n",
    "    axs[1].set_xlabel('Feature 1')\n",
    "    axs[1].set_ylabel('Feature 2')\n",
    "    cbar = fig.colorbar(scatter, ax=axs[1], ticks=range(n_components))\n",
    "    cbar.set_label('Cluster Label')\n",
    "    \n",
    "    plt.suptitle(f'GMM Results at Epoch {epoch}', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder}/gmm_results_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_gmm_generated_samples(gmm, epoch, n_samples=1000):\n",
    "    # Generate samples from the GMM\n",
    "    gmm_samples, gmm_labels = gmm.sample(n_samples=n_samples)\n",
    "    gmm_samples = gmm_samples.cpu().numpy()\n",
    "    gmm_labels = gmm_labels.cpu().numpy()\n",
    "    \n",
    "    n_components = gmm.n_components\n",
    "    cmap = plt.get_cmap('tab20', n_components)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Left Plot: Per-Sample Log Likelihood\n",
    "    log_probs = gmm.score_samples(torch.from_numpy(gmm_samples).to(gmm.device))\n",
    "    scatter = axs[0].scatter(gmm_samples[:, 0], gmm_samples[:, 1], c=log_probs.cpu().numpy(), cmap='viridis', s=10, alpha=.5)\n",
    "    axs[0].set_title('Per-Sample Log-Likelihood (Generated Samples)')\n",
    "    axs[0].set_xlabel('Feature 1')\n",
    "    axs[0].set_ylabel('Feature 2')\n",
    "    cbar = fig.colorbar(scatter, ax=axs[0])\n",
    "    cbar.set_label('Log-Likelihood')\n",
    "    \n",
    "    # Right Plot: Cluster Labels\n",
    "    scatter = axs[1].scatter(gmm_samples[:, 0], gmm_samples[:, 1], c=gmm_labels, cmap=cmap, s=10, alpha=.5)\n",
    "    axs[1].set_title('Generated Samples with Cluster Labels')\n",
    "    axs[1].set_xlabel('Feature 1')\n",
    "    axs[1].set_ylabel('Feature 2')\n",
    "    cbar = fig.colorbar(scatter, ax=axs[1], ticks=range(n_components))\n",
    "    cbar.set_label('Cluster Label')\n",
    "    \n",
    "    plt.suptitle(f'GMM Generated Samples at Epoch {epoch}', size=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder}/gmm_generated_samples_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_gmm_component_probabilities(X, gmm, title_prefix, epoch):\n",
    "    X = X.detach().cpu().numpy()\n",
    "    probs = gmm.predict_proba(torch.from_numpy(X).to(gmm.device)).detach().cpu().numpy()\n",
    "    n_components = gmm.n_components\n",
    "    n_cols = 2\n",
    "    n_rows = (n_components + 1) // n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(12, 5 * n_rows))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for k, ax in enumerate(axs):\n",
    "        if k < n_components:\n",
    "            prob_k = probs[:, k]\n",
    "            scatter = ax.scatter(X[:, 0], X[:, 1], c=prob_k, cmap='viridis', s=1, alpha=0.2)\n",
    "            ax.set_title(f'Component {k+1} Probability')\n",
    "            ax.set_xlabel('Feature 1')\n",
    "            ax.set_ylabel('Feature 2')\n",
    "            cbar = fig.colorbar(scatter, ax=ax)\n",
    "            cbar.set_label('Probability')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    fig.suptitle(f\"{title_prefix} Probability Distributions Across GMM Components at Epoch {epoch}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig(f'{folder}/gmm_component_probabilities_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n",
    "\n",
    "def get_covariance_matrix(gmm, n):\n",
    "    if gmm.covariance_type == 'full':\n",
    "        cov = gmm.covariances_[n].detach().cpu().numpy()\n",
    "    elif gmm.covariance_type == 'tied':\n",
    "        cov = gmm.covariances_.detach().cpu().numpy()\n",
    "    elif gmm.covariance_type == 'diag':\n",
    "        cov = np.diag(gmm.covariances_[n].detach().cpu().numpy())\n",
    "    elif gmm.covariance_type == 'spherical':\n",
    "        cov = np.eye(gmm.n_features) * gmm.covariances_[n].detach().cpu().numpy()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported covariance type\")\n",
    "    return cov\n",
    "\n",
    "def plot_covariance_ellipse(ax, mean, cov, n_std=1, **kwargs):\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "    width, height = 2 * n_std * np.sqrt(vals)\n",
    "    ellipse = Ellipse(xy=mean, width=width, height=height, angle=theta, **kwargs)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "\n",
    "def plot_gmm_contours(gmm, X, epoch):\n",
    "    X = X.detach().cpu().numpy()\n",
    "    n_components = gmm.n_components\n",
    "    colors = plt.cm.get_cmap('tab20', n_components)\n",
    "    means = gmm.means_.detach().cpu().numpy()\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # First Plot\n",
    "    ax = axs[0]\n",
    "    ax.scatter(X[:, 0], X[:, 1], c='black', s=1, zorder=1, alpha=0.2, label='Representations')\n",
    "    ax.scatter(means[:, 0], means[:, 1], marker='x', color='red', s=50, zorder=2, label='GMM Means')\n",
    "    \n",
    "    for n in range(n_components):\n",
    "        mean = means[n]\n",
    "        cov = get_covariance_matrix(gmm, n)\n",
    "        plot_covariance_ellipse(ax, mean, cov, edgecolor='red', linestyle='--', zorder=3, facecolor='none')\n",
    "    \n",
    "    ax.set_title('GMM Means and Covariances')\n",
    "    ax.legend()\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    # Second Plot\n",
    "    ax = axs[1]\n",
    "    for n in range(n_components):\n",
    "        mean = means[n]\n",
    "        cov = get_covariance_matrix(gmm, n)\n",
    "        std = 1\n",
    "        plot_covariance_ellipse(ax, mean, cov, n_std=std, edgecolor=colors(n), facecolor=colors(n, alpha=0.5), zorder=2)\n",
    "    \n",
    "    ax.set_title('GMM Components')\n",
    "    ax.axis('equal')\n",
    "    plt.suptitle(f'Gaussian Mixture at Epoch {epoch}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{folder}/gmm_contours_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 262\u001b[0m\n\u001b[1;32m    258\u001b[0m testrep_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(test_rep\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mrep_lr, betas\u001b[38;5;241m=\u001b[39mrep_betas, amsgrad\u001b[38;5;241m=\u001b[39mrep_amsgrad)\n\u001b[1;32m    260\u001b[0m optimizers \u001b[38;5;241m=\u001b[39m [decoder_optimizer, rep_optimizer, testrep_optimizer]\n\u001b[0;32m--> 262\u001b[0m decoder, gmm, rep, test_rep \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_epoch_gmm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_epoch_gmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefit_gmm_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit_gmm_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_skip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_skip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_gmm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_gmm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 42\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(train_loader, test_loader, model, gmm, rep, test_rep, optimizers, n_epochs, first_epoch_gmm, refit_gmm_interval, plot_step, plot_skip, lambda_gmm, n_images, metrics_list)\u001b[0m\n\u001b[1;32m     40\u001b[0m     loss \u001b[38;5;241m=\u001b[39m recon_loss_x\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     gmm_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mlambda_gmm \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mgmm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m=\u001b[39m recon_loss_x \u001b[38;5;241m+\u001b[39m gmm_error\n\u001b[1;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Downloads/Master Thesis/TorchGMM/utils/gmm.py:593\u001b[0m, in \u001b[0;36mGaussianMixture.score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    Compute the log-likelihood of each sample.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m     _, log_prob_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_prob_norm\n",
      "File \u001b[0;32m~/Downloads/Master Thesis/TorchGMM/utils/gmm.py:270\u001b[0m, in \u001b[0;36mGaussianMixture._e_step\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    268\u001b[0m diff \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeans_\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     cholesky \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariances_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCholesky decomposition failed. Check covariance matrices. Details: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_loop(train_loader, test_loader, model, gmm, rep, test_rep, optimizers, n_epochs, first_epoch_gmm=1, refit_gmm_interval=None, plot_step=None, plot_skip=0, lambda_gmm=1.0, n_images = 20, metrics_list=None):\n",
    "    assert first_epoch_gmm >= 1, \"First epoch for GMM training should be at least 1.\" \n",
    "    start_time = time.time()\n",
    "    \n",
    "    model_optimizer, rep_optimizer, testrep_optimizer = optimizers\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    gmm_train_losses = []\n",
    "    gmm_test_losses = []\n",
    "    recon_train_losses = []\n",
    "    recon_test_losses = []\n",
    "\n",
    "    # Select a fixed set of random images for visualization\n",
    "    fixed_train_img, fixed_train_labels, fixed_train_indices = select_random_images(train_loader, device, num_images=n_components)\n",
    "    fixed_test_img, fixed_test_labels, fixed_test_indices = select_random_images(test_loader, device, num_images=n_components)\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        train_losses.append(0)\n",
    "        test_losses.append(0)\n",
    "        gmm_train_losses.append(0)\n",
    "        gmm_test_losses.append(0)\n",
    "        recon_train_losses.append(0)\n",
    "        recon_test_losses.append(0)\n",
    "\n",
    "        # Training loop\n",
    "        rep_optimizer.zero_grad()\n",
    "        for i, (index, x, labels_batch) in enumerate(train_loader):\n",
    "            model_optimizer.zero_grad()\n",
    "\n",
    "            x, index, labels_batch = x.to(device), index.to(device), labels_batch.to(device)\n",
    "            z = rep(index)\n",
    "            y = model(z)\n",
    "            recon_loss_x = F.binary_cross_entropy(y, x, reduction='sum')\n",
    "\n",
    "            if epoch < first_epoch_gmm:\n",
    "                gmm_error = torch.tensor(0.0, device=device)\n",
    "                loss = recon_loss_x\n",
    "            else:\n",
    "                gmm_error = -lambda_gmm * torch.mean(gmm.score_samples(z))\n",
    "                loss = recon_loss_x + gmm_error\n",
    "\n",
    "            loss.backward()\n",
    "            model_optimizer.step()\n",
    "\n",
    "            train_losses[-1] += loss.item() * x.size(0)\n",
    "            gmm_train_losses[-1] += gmm_error.item() * x.size(0)\n",
    "            recon_train_losses[-1] += recon_loss_x.item()\n",
    "\n",
    "        rep_optimizer.step()\n",
    "\n",
    "        # Testing loop\n",
    "        testrep_optimizer.zero_grad()\n",
    "        for i, (index, x, _) in enumerate(test_loader):\n",
    "            x, index = x.to(device), index.to(device)\n",
    "            z = test_rep(index)\n",
    "            y = model(z)\n",
    "            recon_loss_x = F.binary_cross_entropy(y, x, reduction='sum')\n",
    "            if epoch < first_epoch_gmm:\n",
    "                gmm_error = torch.tensor(0.0, device=device)\n",
    "                loss = recon_loss_x\n",
    "            else:\n",
    "                gmm_error = -lambda_gmm * torch.mean(gmm.score_samples(z))\n",
    "                loss = recon_loss_x + gmm_error\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            test_losses[-1] += loss.item() * x.size(0)\n",
    "            gmm_test_losses[-1] += gmm_error.item() * x.size(0)\n",
    "            recon_test_losses[-1] += recon_loss_x.item()\n",
    "\n",
    "        testrep_optimizer.step()\n",
    "\n",
    "        if epoch == first_epoch_gmm:\n",
    "            with torch.no_grad():\n",
    "                representations = rep.z.detach().to(device)\n",
    "                gmm.fit(representations, max_iter=100)\n",
    "        \n",
    "        elif epoch > first_epoch_gmm:\n",
    "            with torch.no_grad():\n",
    "                representations = rep.z.detach().to(device)\n",
    "                if refit_gmm_interval and epoch % refit_gmm_interval == 0:\n",
    "                    gmm = GaussianMixture(n_features=n_features, n_components=n_components, covariance_type=covariance_type, init_params=init_params, device=device)\n",
    "                    gmm.fit(representations, max_iter=100)\n",
    "                else:\n",
    "                    gmm.fit(representations, max_iter=10, warm_start=True)\n",
    "\n",
    "        # Average the losses\n",
    "        train_losses[-1] /= len(train_loader.dataset)\n",
    "        test_losses[-1] /= len(test_loader.dataset)\n",
    "        gmm_train_losses[-1] /= len(train_loader.dataset)\n",
    "        gmm_test_losses[-1] /= len(test_loader.dataset)\n",
    "        recon_train_losses[-1] /= len(train_loader.dataset)\n",
    "        recon_test_losses[-1] /= len(test_loader.dataset)\n",
    "\n",
    "        # Timing calculations\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        total_time_elapsed = time.time() - start_time\n",
    "        avg_epoch_time = total_time_elapsed / epoch\n",
    "        remaining_epochs = n_epochs - epoch\n",
    "        estimated_time_left = avg_epoch_time * remaining_epochs\n",
    "        estimated_finish_time = start_time + total_time_elapsed + estimated_time_left\n",
    "\n",
    "        print(f\"Epoch {epoch}/{n_epochs} - GMM Loss: {gmm_train_losses[-1]:.4f} / {gmm_test_losses[-1]:.4f} - \"\n",
    "              f\"Recon Loss: {recon_train_losses[-1]:.4f} / {recon_test_losses[-1]:.4f} - \"\n",
    "              f\"GMM Convergence: {gmm.converged_} ({gmm.n_iter_+1}) - \"\n",
    "              f\"TpE: {timedelta(seconds=int(epoch_time))} - \"\n",
    "              f\"RT: {timedelta(seconds=int(estimated_time_left))} - \"\n",
    "              f\"ETA: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(estimated_finish_time))}\")        \n",
    "\n",
    "        if (plot_step and epoch % plot_step == 0 and epoch > plot_skip) or epoch == n_epochs:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # Plot the losses\n",
    "                plot_loss(gmm_train_losses, gmm_test_losses, recon_train_losses, recon_test_losses, epoch)\n",
    "\n",
    "                # Get representations and labels\n",
    "                representations = rep.z.detach()\n",
    "                test_representations = test_rep.z.detach()\n",
    "                labels = all_labels.cpu()\n",
    "                with torch.no_grad():\n",
    "                    recon_fixed_train = model(representations[:n_images]).squeeze().detach().cpu()\n",
    "                    recon_fixed_test = model(test_representations[:n_images]).squeeze().detach().cpu()\n",
    "\n",
    "                # Generate GMM means and samples\n",
    "                sampled, sampled_labels = gmm.sample(n_components)\n",
    "                sampled_imgs = [model(sample.unsqueeze(0)).squeeze().detach().cpu() for sample in sampled]\n",
    "                gmm_means_imgs = [model(mean.unsqueeze(0)).squeeze().detach().cpu() for mean in gmm.means_]\n",
    "\n",
    "                # Define titles and corresponding image sets\n",
    "                titles = [\n",
    "                    \"Cluster Centers\",\n",
    "                    \"New Samples\",\n",
    "                    \"Reconstructed Train Images\",\n",
    "                    \"Reconstructed Test Images\",\n",
    "                    \"Original Train Images\",\n",
    "                    \"Original Test Images\"\n",
    "                ]\n",
    "                image_sets = [\n",
    "                    gmm_means_imgs,\n",
    "                    sampled_imgs,\n",
    "                    recon_fixed_train[:n_components],  # Reconstructed Train Images\n",
    "                    recon_fixed_test[:n_components],   # Reconstructed Test Images\n",
    "                    fixed_train_img[:n_components],    # Original Train Images\n",
    "                    fixed_test_img[:n_components]      # Original Test Images\n",
    "                ]\n",
    "\n",
    "                # Call the plotting function for each set\n",
    "                for imgs, title in zip(image_sets, titles):\n",
    "                    plot_images(imgs, title, epoch, cmap='viridis')  # Use 'gray_r' colormap\n",
    "\n",
    "                if epoch == n_epochs:\n",
    "                    plot_latent_space_visualizations(\n",
    "                        representations, labels, n_features, epoch, fraction=1, s=1, alpha=1,\n",
    "                        perplexity=20, gmm_means=gmm.means_.detach().cpu().numpy()\n",
    "                    )\n",
    "                else:\n",
    "                    plot_latent_space_visualizations(\n",
    "                        representations, labels, n_features, epoch, fraction=0.05, s=1, alpha=1,\n",
    "                        perplexity=20, gmm_means=gmm.means_.detach().cpu().numpy()\n",
    "                    )\n",
    "                \n",
    "                plot_gmm_results(representations, gmm, epoch)\n",
    "                plot_gmm_generated_samples(gmm, epoch)\n",
    "\n",
    "                X = rep.z.detach()\n",
    "                true_labels = all_labels.cpu()\n",
    "\n",
    "                # Evaluate clustering\n",
    "                results = gmm.evaluate_clustering(X, true_labels=true_labels, metrics=metrics_list)\n",
    "\n",
    "                # Print metrics\n",
    "                for metric, score in results.items():\n",
    "                    if metric != 'confusion_matrix' and metric != 'classification_report':\n",
    "                        print(f\"{metric}: {score}\")\n",
    "\n",
    "                # Confusion matrix\n",
    "                cm = results['confusion_matrix']\n",
    "\n",
    "                # Plot confusion matrix\n",
    "                import seaborn as sns\n",
    "\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "                plt.xlabel('Predicted Labels')\n",
    "                plt.ylabel('True Labels')\n",
    "                plt.title('Confusion Matrix')\n",
    "                plt.savefig(f'{folder}/confusion_matrix_epoch_{epoch}.pdf', format='pdf', dpi=400)\n",
    "                plt.show()\n",
    "\n",
    "                \n",
    "            model.train()\n",
    "\n",
    "    model.eval()\n",
    "    print('Training completed.')\n",
    "    return model, gmm, rep, test_rep\n",
    "\n",
    "metrics_list = [\n",
    "    \"rand_score\",\n",
    "    \"adjusted_rand_score\",\n",
    "    \"mutual_info_score\",\n",
    "    \"normalized_mutual_info_score\",\n",
    "    \"adjusted_mutual_info_score\",\n",
    "    \"fowlkes_mallows_score\",\n",
    "    \"homogeneity_score\",\n",
    "    \"completeness_score\",\n",
    "    \"v_measure_score\",\n",
    "    \"purity_score\",\n",
    "    \"classification_report\",\n",
    "    \"confusion_matrix\",\n",
    "    \"bic_score\",\n",
    "    \"aic_score\",\n",
    "    # Exclude 'silhouette_score', 'davies_bouldin_index', 'calinski_harabasz_score', 'dunn_index'\n",
    "]\n",
    "\n",
    "# Initialize components\n",
    "n_features = 5\n",
    "n_components = 20\n",
    "epochs = 300\n",
    "plot_step = 50\n",
    "plot_skip = 0\n",
    "first_epoch_gmm = 1\n",
    "refit_gmm_interval = 50\n",
    "nsample = len(indexed_train_dataset)\n",
    "nsample_test = len(indexed_test_dataset)\n",
    "lambda_gmm = 1.0\n",
    "\n",
    "# Adam Parameters\n",
    "decoder_lr = 5e-3\n",
    "rep_lr = 5e-2\n",
    "decoder_weight_decay = 1e-5\n",
    "decoder_betas = (0.9, 0.999)\n",
    "rep_betas = (0.9, 0.999)\n",
    "decoder_amsgrad = True\n",
    "rep_amsgrad =False\n",
    "\n",
    "# GMM Parameters\n",
    "covariance_type = 'full'\n",
    "init_params = 'kmeans'\n",
    "    \n",
    "# Decoder Parameters\n",
    "dropout = 0.1\n",
    "batch_norm = False\n",
    "fourier_dim = None\n",
    "scale = 1\n",
    "\n",
    "gmm = GaussianMixture(n_features=n_features, n_components=n_components, covariance_type=covariance_type, init_params=init_params, device=device)\n",
    "\n",
    "rep = RepresentationLayer(values=torch.randn(size=(nsample, n_features)).to(device))\n",
    "test_rep = RepresentationLayer(values=torch.randn(size=(nsample_test, n_features)).to(device))\n",
    "\n",
    "decoder = ConvDecoder(latent_dim=n_features, fourier_dim=fourier_dim, scale=scale, dropout=dropout, batch_norm=batch_norm).to(device)\n",
    "\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=decoder_lr, betas=decoder_betas, amsgrad=decoder_amsgrad, weight_decay=decoder_weight_decay)\n",
    "rep_optimizer = torch.optim.Adam(rep.parameters(), lr=rep_lr, betas=rep_betas, amsgrad=rep_amsgrad)\n",
    "testrep_optimizer = torch.optim.Adam(test_rep.parameters(), lr=rep_lr, betas=rep_betas, amsgrad=rep_amsgrad)\n",
    "\n",
    "optimizers = [decoder_optimizer, rep_optimizer, testrep_optimizer]\n",
    "\n",
    "decoder, gmm, rep, test_rep = train_loop(train_loader, test_loader, decoder, gmm, rep, test_rep, optimizers, n_epochs=epochs, first_epoch_gmm=first_epoch_gmm, refit_gmm_interval=refit_gmm_interval, plot_step=plot_step, plot_skip=plot_skip, lambda_gmm=lambda_gmm, metrics_list=metrics_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
